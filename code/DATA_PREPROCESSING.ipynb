{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[step0] DATA PREPROCESSING",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING:\n",
        "\n",
        "- verify data quality (NaN, useless features and so on) ✅\n",
        "- Encoding categorical features ✅\n",
        "- Unbalancing Data for sperimentation ✅"
      ],
      "metadata": {
        "id": "k03uKfo0ZcbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrFq6WRSV6L1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import random \n",
        "import time\n",
        "from collections import defaultdict\n",
        "from scipy.stats.stats import pearsonr\n",
        "import pandas_profiling\n",
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, roc_curve, auc, plot_confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "# evaluate model performance with outliers removed using isolation forest\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.special import expit\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB\n",
        "import sklearn\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pydotplus\n",
        "from sklearn import tree\n",
        "from IPython.display import Image\n",
        "custom_scorer = make_scorer(f1_score, greater_is_better=True, pos_label=0)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.constraints import maxnorm\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2ceVD6IY_jQ",
        "outputId": "e7485d34-f67c-47bb-f58d-dee8280cb8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define path for data.\n",
        "dir = 'ecoli_sup'\n",
        "filename = 'ecoli'\n",
        "directory = '/content/drive/My Drive/TESI_LUSITO/benchmark_data/'+dir+'/'"
      ],
      "metadata": {
        "id": "VD9qrvV_ZCT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv(directory+filename+'.csv', delimiter=';') #load data\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "1LvMBspYZDz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop useless or corrupted features\n",
        "df_1.drop('feature1', inplace=True, axis=1)\n",
        "\n",
        "#rename features in \" feature_n \" format (class must be manually renamed)\n",
        "df_1.columns = ['feature_{}'.format(i) for i in range(df_1.shape[1])]\n",
        "\n",
        "#class column to rename\n",
        "df_1.rename(columns = {'feature_7':'class'}, inplace = True)\n",
        "df_1.rename(columns = {'feature_8': 'outlier'}, inplace=True)\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "klOFLOxBQTz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for null values\n",
        "print('Null Values in DataSet:')\n",
        "print(df_1.isnull().sum())\n",
        "print('\\nRows: ',df_1.shape[0])\n",
        "print('Columns: ',df_1.shape[1])"
      ],
      "metadata": {
        "id": "QZslIB64ZyAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNBALANCING DATA "
      ],
      "metadata": {
        "id": "lhFo4dY5aaaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.histogram(df_1, x=\"class\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ARdTsZfmacm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ENCODING CATEGORICAL FEATURES"
      ],
      "metadata": {
        "id": "QD8e0krdaQL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.dtypes"
      ],
      "metadata": {
        "id": "4GNPrrdNaT1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "analyze categorical attributes to check quality"
      ],
      "metadata": {
        "id": "_1oPtr13YAqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical features\n",
        "print(df_1['class'].unique())\n",
        "#print(df_1['feature_0'].unique())"
      ],
      "metadata": {
        "id": "O9709LkNYDka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IF THERE ARE ERRORS IN CATEGORICAL DATA, LET'S DO SOME ADJUSTMENTS\n",
        "\n",
        "# df_1[\"feature5\"] = df_1[\"feature5\"].replace({'Blue white':'Blue-White', \n",
        "#                                      'Blue-white' :'Blue-White', 'Blue-white': 'Blue-White', 'Blue White': 'Blue-White'})\n",
        "\n",
        "# df_1[\"feature5\"] = df_1[\"feature5\"].replace({'yellow-white':'White-Yellow', 'yellowish': 'Yellowish', 'white': 'White'})"
      ],
      "metadata": {
        "id": "GkFBfK4CYpau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_1[\"feature_0\"] = df_1[\"feature_0\"].astype('category')\n",
        "df_1[\"class\"] = df_1[\"class\"].astype('category')\n",
        "\n",
        "#print(df_1['feature_0'].unique())\n",
        "print(df_1['class'].unique())\n",
        "print('--- . --- . --- . ---')\n",
        "\n",
        "\n",
        "#perform encoding on columns\n",
        "#df_1['feature_0'] = df_1['feature_0'].cat.codes\n",
        "df_1[\"class\"] = df_1[\"class\"].cat.codes\n",
        "print(df_1['class'].unique())\n",
        "#print(df_1['feature_0'].unique())\n",
        "\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "F3AFo-4naX4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.histogram(df_1, x=\"class\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "v4Lw0bHVertG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RARE CASE WHEN CLASS IS COMPOSED JUST OF 1 RECORD\n",
        "# df_1 = df_1.drop(df_1[df_1['class'] == 3].index)"
      ],
      "metadata": {
        "id": "GPc18fwTDjzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMALIZE ORIGINAL DATA"
      ],
      "metadata": {
        "id": "eUYdFoUATk97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize outlierness scores\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "# create a scaler object\n",
        "scaler = RobustScaler()\n",
        "\n",
        "#categorical features must not be normalized\n",
        "target = df_1['class']\n",
        "outlier = df_1['outlier']\n",
        "#cat_1 = df_1['feature_0']\n",
        "\n",
        "df_1.drop('class', inplace=True, axis=1)\n",
        "df_1.drop('outlier', inplace=True, axis=1)\n",
        "#df_1.drop('feature_0', inplace=True, axis=1)\n",
        "\n",
        "# fit and transform the data\n",
        "df_1[df_1.columns] = scaler.fit_transform(df_1[df_1.columns])\n",
        "\n",
        "df_1['class'] = target\n",
        "df_1['outlier'] = outlier\n",
        "#df_1['feature_0'] = cat_1\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "aRxIbMPlTm-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataname_clean = filename+'_clean'+'.csv'\n",
        "df_1.to_csv(directory+dataname_clean)"
      ],
      "metadata": {
        "id": "v1aIcVqNfIb5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}