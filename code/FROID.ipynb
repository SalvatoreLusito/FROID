{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVbkG54Q9TEL"
      },
      "source": [
        "# IMPORT LIBRARIES AND FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZgEO-y1VfME"
      },
      "outputs": [],
      "source": [
        "!pip install pyod\n",
        "!pip install combo\n",
        "!pip install suod\n",
        "!pip install pynomaly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwwM5dIC8SCx"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import random \n",
        "import time\n",
        "from collections import defaultdict\n",
        "from scipy.stats.stats import pearsonr\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, roc_curve, auc, plot_confusion_matrix, roc_auc_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from PyNomaly import loop\n",
        "\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# evaluate model performance with outliers removed using isolation forest\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from pyod.models.knn import KNN   # kNN detector\n",
        "import pyod\n",
        "from pyod.utils.data import generate_data\n",
        "from pyod.utils.utility import score_to_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmSiOgLI5hlg"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj-2hD9Zldra"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlthKTNg9Xb9"
      },
      "source": [
        "# IMPORT DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3fb7Wwlfgg1"
      },
      "outputs": [],
      "source": [
        "directory = '/content/drive/My Drive/TESI_LUSITO/benchmark_data/yeast/'\n",
        "dataname = 'yeast_clean.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_3HvJKu7_no"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(directory+dataname, delimiter=',') #load data\n",
        "data.drop('Unnamed: 0', inplace=True, axis=1)\n",
        "#data.drop('outlier', inplace=True, axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT0SnETRnbpo"
      },
      "outputs": [],
      "source": [
        "target = data['class']\n",
        "data.drop('class', inplace=True, axis=1) \n",
        "\n",
        "#supervised?\n",
        "#data.drop('outlier', inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wf4nrXner8I"
      },
      "source": [
        "#OUTLIERNESS SCORES EXTRACTION ON ORIGINAL DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl37YIJeiF-W"
      },
      "source": [
        "##pynomaly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj3fy11r1Z3B"
      },
      "outputs": [],
      "source": [
        "scores_df = pd.DataFrame()\n",
        "binary_scores_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQG7wC7o1NSS"
      },
      "outputs": [],
      "source": [
        "def pynomaly_methods(data, scores_df, binary_scores_df):\n",
        "  #no parameters to test\n",
        "  try:\n",
        "    m = loop.LocalOutlierProbability(data, progress_bar=True).fit()\n",
        "    scores = m.local_outlier_probabilities\n",
        "    scores_df['pynomaly_loop_original'] = scores\n",
        "    binary_scores_df['pynomaly_loop_original_binary'] = scores\n",
        "    binary_scores_df['pynomaly_loop_original_binary'] = np.where(binary_scores_df['pynomaly_loop_original_binary']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOP Config 1')\n",
        "\n",
        "  #parameters to test:\n",
        "  # -eps/min_samples for DBSCAN\n",
        "  # -extend/n_neighbors for LOP\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps01_sam10_nei10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam10_nei10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam10_nei10_e1'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps01_sam10_nei10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 1')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps01_sam20_nei10_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam20_nei10_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam20_nei10_e2'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps01_sam20_nei10_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 2')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.1, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, n_neighbors=20, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps01_sam20_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam20_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam20_nei20_e2'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps01_sam20_nei20_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 3')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps01_sam50_nei10_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei10_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei10_e3'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei10_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 4')\n",
        "\n",
        "  try: \n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=20, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps01_sam50_nei20_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei20_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei20_e3'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei20_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 5')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=50, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps01_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei50_e3'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps01_sam50_nei50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 6')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilitiesscores_df['dbscan_scores_original_eps03_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam10_e1'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps03_sam10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 7')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps03_sam20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam20_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam20_e1'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps03_sam20_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 8')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2,  cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps03_sam50_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e2'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 9')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3,cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e3'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 10')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_original_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e3'] = np.where(binary_scores_df['dbscan_scores_original_binary_eps03_sam50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 11')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53YmYDLOmhIq"
      },
      "source": [
        "##sklearn algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3rqDDJl4g0t"
      },
      "outputs": [],
      "source": [
        "def sklearn_methods(data, scores_df, binary_scores_df):\n",
        "  #Minimum Covariance Determinant\n",
        "  try:\n",
        "    ee = EllipticEnvelope(contamination=0.001)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_original_cont0.001'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_original_cont0.001'] = maha\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.001'] = pred\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.001'] = np.where(binary_scores_df['elliptic_env_original_binary_cont0.001']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 1')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.01)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_original_cont0.01'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_original_cont0.01'] = maha\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.01'] = pred\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.01'] = np.where(binary_scores_df['elliptic_env_original_binary_cont0.01']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 2')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.1)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_original_cont0.1'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_original_cont0.1'] = maha\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.1'] = pred\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.1'] = np.where(binary_scores_df['elliptic_env_original_binary_cont0.1']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 3')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.2)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_original_cont0.2'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_original_cont0.2'] = maha\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.2'] = pred\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.2'] = np.where(binary_scores_df['elliptic_env_original_binary_cont0.2']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 4')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.5)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_original_cont0.5'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_original_cont0.5'] = maha\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.5'] = pred\n",
        "    binary_scores_df['elliptic_env_original_binary_cont0.5'] = np.where(binary_scores_df['elliptic_env_original_binary_cont0.5']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 5')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.001, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_original_cont0.001'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.001'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.001'] = np.where(binary_scores_df['iso_forest_paper_score_original_binary_cont0.001']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 1')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.01, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_original_cont0.01'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.01'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.01'] = np.where(binary_scores_df['iso_forest_paper_score_original_binary_cont0.01']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 2')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.1, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_original_cont0.1'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.1'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.1'] = np.where(binary_scores_df['iso_forest_paper_score_original_binary_cont0.1']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 3')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.2, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_original_cont0.2'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.2'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.2'] = np.where(binary_scores_df['iso_forest_paper_score_original_binary_cont0.2']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 4')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.5, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_original_cont0.5'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.5'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_original_binary_cont0.5'] = np.where(binary_scores_df['iso_forest_paper_score_original_binary_cont0.5']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 5')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=10, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['lof_score_original_mink_nei10'] = lof_score\n",
        "    binary_scores_df['lof_score_original_binary_mink_nei10'] = pred\n",
        "    binary_scores_df['lof_score_original_binary_mink_nei10'] = np.where(binary_scores_df['lof_score_original_binary_mink_nei10']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 1')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=20, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['lof_score_original_mink_nei20'] = lof_score\n",
        "    binary_scores_df['lof_score_original_binary_mink_nei20'] = pred\n",
        "    binary_scores_df['lof_score_original_binary_mink_nei20'] = np.where(binary_scores_df['lof_score_original_binary_mink_nei20']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 2')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=50, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['lof_score_original_mink_nei50'] = lof_score\n",
        "    binary_scores_df['lof_score_original_binary_mink_nei50'] = pred\n",
        "    binary_scores_df['lof_score_original_binary_mink_nei50'] = np.where(binary_scores_df['lof_score_original_binary_mink_nei50']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 3')\n",
        "\n",
        "  from sklearn.svm import OneClassSVM\n",
        "  # try:\n",
        "  #   #One Class SVM\n",
        "  #   ee = OneClassSVM(nu=0.001, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_original_linear_nu0.001'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_linear_nu0.001'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_linear_nu0.001'] = np.where(binary_scores_df['oneclass_SVM_original_binary_linear_nu0.001']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 1')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.01, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_original_linear_nu0.01'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_linear_nu0.01'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_linear_nu0.01'] = np.where(binary_scores_df['oneclass_SVM_original_binary_linear_nu0.01']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 2')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.1, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_original_linear_nu0.1'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_linear_nu0.1'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_linear_nu0.1'] = np.where(binary_scores_df['oneclass_SVM_original_binary_linear_nu0.1']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 3')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.001)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_original_rbf_nu0.001'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.001'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.001'] = np.where(binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.001']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 4')\n",
        "\n",
        "  # try:  \n",
        "  #   ee = OneClassSVM(nu=0.01)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_original_rbf_nu0.01'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.01'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.01'] = np.where(binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.01']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 5')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.1)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_original_rbf_nu0.1'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.1'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.1'] = np.where(binary_scores_df['oneclass_SVM_original_binary_rbf_nu0.1']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IubCDytiCbG"
      },
      "source": [
        "##pyod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uMYCNPq5sp0"
      },
      "outputs": [],
      "source": [
        "from pyod.models.mcd import MCD\n",
        "from pyod.models.suod import SUOD\n",
        "from pyod.models.loda import LODA\n",
        "from pyod.models.feature_bagging import FeatureBagging\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.cof import COF\n",
        "from pyod.models.copod import COPOD\n",
        "from pyod.models.ecod import ECOD\n",
        "from pyod.models.sos import SOS\n",
        "from pyod.models.pca import PCA\n",
        "\n",
        "def pyod_methods(data, scores_df, binary_scores_df):\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_original_cont0.001'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_original_cont0.01'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_original_cont0.1'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_original_cont0.2'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_original_cont0.5'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_original_cont0.001'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_original_cont0.01'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_original_cont0.1'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_original_cont0.2'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_original_cont0.5'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_original_cont0.001'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_original_cont0.01'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_original_cont0.1'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_original_cont0.2'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_original_cont0.5'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.001_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.001_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 1 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.01_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.01_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 2 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.1_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.1_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 3 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.2_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.2_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 4 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.5_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.5_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 5 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.001_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.001_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 6 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.01_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.01_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 7 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.1_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.1_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 8 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.2_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.2_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 9 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_original_cont0.5_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_original_binary_cont0.5_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 10 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_original_cont0.001'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_original_cont0.01'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_original_cont0.1'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_original_cont0.2'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_original_cont0.5'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.001_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.001_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.01_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.01_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.1_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.1_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.2_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.2_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.5_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.5_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.001_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.001_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.001_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.001_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 7')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.001_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.001_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.01_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.001_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.01_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.001_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 10')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.01_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.001_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 11')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.1_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.1_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 12')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.1_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.1_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 13')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.1_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.1_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 14')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.2_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.2_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 15')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.2_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.2_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 16')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.2_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.2_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 17')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.5_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.5_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 18')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.5_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.5_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 19')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_original_cont0.5_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_original_binary_cont0.5_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 20')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.001_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.001_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.01_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.01_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.1_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.1_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.2_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.2_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.5_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.5_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.001_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.001_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.01_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.01_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 7')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.1_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.1_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.2_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.2_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.5_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.5_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 10')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.001_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.001_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 11')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.01_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.01_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 12')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.1_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.1_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 13')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.2_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.2_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 14')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_original_cont0.5_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_original_binary_cont0.5_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 15')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_original_cont0.001'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 1')\n",
        "\n",
        "  try:  \n",
        "    clf = CBLOF(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_original_cont0.01'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_original_cont0.1'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_original_cont0.2'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_original_cont0.5'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_original_cont0.001'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_original_cont0.01'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_original_cont0.1'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_original_cont0.2'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_original_cont0.5'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_original_cont0.001'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_original_cont0.01'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 2')\n",
        "\n",
        "  try:  \n",
        "    clf = KNN(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_original_cont0.1'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_original_cont0.2'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_original_cont0.5'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_original_cont0.001'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_original_cont0.01'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_original_cont0.1'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_original_cont0.2'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_original_cont0.5'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_original_cont0.001'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_original_cont0.01'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_original_cont0.1'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_original_cont0.2'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_original_cont0.5'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_original_cont0.001'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_original_cont0.01'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_original_cont0.1'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_original_cont0.2'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_original_cont0.5'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMFjoc6umjPl"
      },
      "source": [
        "##network methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVepkv7gdsE0"
      },
      "outputs": [],
      "source": [
        "#autoencoder method - (improve network)\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "def network_methods(data):\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_original_cont0.001'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_original_cont0.01'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_original_cont0.1'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_original_cont0.2'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_original_cont0.5'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  #vae method\n",
        "  from pyod.models.vae import VAE\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_original_cont0.001'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_original_cont0.01'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_original_cont0.1'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_original_cont0.2'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_original_cont0.5'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  #so_gaal method\n",
        "  from pyod.models.so_gaal import SO_GAAL\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.001, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.001_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.001_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.01, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.01_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.01_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.1_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.1_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.2, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.2_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.2_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.5, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.5_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.5_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.1_lrd0.01_lrg0.01_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.1_lrd0.01_lrg0.01_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.3 , lr_g=0.3 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.1_lrd0.3_lrg0.3_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.1_lrd0.3_lrg0.3_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.1_lrd0.01_lrg0.01_mom0.1'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.1_lrd0.01_lrg0.01_mom0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_original_cont0.1_lrd0.01_lrg0.01_mom0.3'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_original_binary_cont0.1_lrd0.01_lrg0.01_mom0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  #deepsvdd method\n",
        "  import pyod.models.deep_svdd\n",
        "  try:\n",
        "    clf = pyod.models.deep_svdd.DeepSVDD(verbose=1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_original'] = pyod_svdd\n",
        "    binary_scores_df['pyod_svdd_original_binary'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  #mo_gaal method\n",
        "  from pyod.models.mo_gaal import MO_GAAL\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_original_cont0.001'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_original_cont0.01'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_original_cont0.1'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_original_cont0.2'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_original_cont0.5'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  #deep_svd method\n",
        "  from pyod.models.deep_svdd import DeepSVDD\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_original_cont0.001'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_original_cont0.01'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_original_cont0.1'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_original_cont0.2'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_original_cont0.5'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm7Spm8f6gIT"
      },
      "source": [
        "#DIMENSIONALITY REDUCTION TECHNIQUES ON ORIGINAL DATA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dueOcyKELpJf"
      },
      "outputs": [],
      "source": [
        "def sammon(x, n, display = 0, inputdist = 'raw', maxhalves = 20, maxiter = 1, tolfun = 1e-9, init = 'default'):\n",
        "\n",
        "    import numpy as np \n",
        "    from scipy.spatial.distance import cdist\n",
        "\n",
        "    \"\"\"Perform Sammon mapping on dataset x\n",
        "    y = sammon(x) applies the Sammon nonlinear mapping procedure on\n",
        "    multivariate data x, where each row represents a pattern and each column\n",
        "    represents a feature.  On completion, y contains the corresponding\n",
        "    co-ordinates of each point on the map.  By default, a two-dimensional\n",
        "    map is created.  Note if x contains any duplicated rows, SAMMON will\n",
        "    fail (ungracefully). \n",
        "    [y,E] = sammon(x) also returns the value of the cost function in E (i.e.\n",
        "    the ess of the mapping).\n",
        "    An N-dimensional output map is generated by y = sammon(x,n) .\n",
        "    A set of optimisation options can be specified using optional\n",
        "    arguments, y = sammon(x,n,[OPTS]):\n",
        "       maxiter        - maximum number of iterations\n",
        "       tolfun         - relative tolerance on objective function\n",
        "       maxhalves      - maximum number of step halvings\n",
        "       input          - {'raw','distance'} if set to 'distance', X is \n",
        "                        interpreted as a matrix of pairwise distances.\n",
        "       display        - 0 to 2. 0 least verbose, 2 max verbose.\n",
        "       init           - {'pca', 'cmdscale', random', 'default'}\n",
        "                        default is 'pca' if input is 'raw', \n",
        "                        'msdcale' if input is 'distance'\n",
        "    The default options are retrieved by calling sammon(x) with no\n",
        "    parameters.\n",
        "    File        : sammon.py\n",
        "    Date        : 18 April 2014\n",
        "    Authors     : Tom J. Pollard (tom.pollard.11@ucl.ac.uk)\n",
        "                : Ported from MATLAB implementation by \n",
        "                  Gavin C. Cawley and Nicola L. C. Talbot\n",
        "    Description : Simple python implementation of Sammon's non-linear\n",
        "                  mapping algorithm [1].\n",
        "    References  : [1] Sammon, John W. Jr., \"A Nonlinear Mapping for Data\n",
        "                  Structure Analysis\", IEEE Transactions on Computers,\n",
        "                  vol. C-18, no. 5, pp 401-409, May 1969.\n",
        "    Copyright   : (c) Dr Gavin C. Cawley, November 2007.\n",
        "    This program is free software; you can redistribute it and/or modify\n",
        "    it under the terms of the GNU General Public License as published by\n",
        "    the Free Software Foundation; either version 2 of the License, or\n",
        "    (at your option) any later version.\n",
        "    This program is distributed in the hope that it will be useful,\n",
        "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "    GNU General Public License for more details.\n",
        "    You should have received a copy of the GNU General Public License\n",
        "    along with this program; if not, write to the Free Software\n",
        "    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n",
        "    \"\"\"\n",
        "\n",
        "    # Create distance matrix unless given by parameters\n",
        "    if inputdist == 'distance':\n",
        "        D = x\n",
        "        if init == 'default':\n",
        "            init = 'cmdscale'\n",
        "    else:\n",
        "        D = cdist(x, x)\n",
        "        if init == 'default':\n",
        "            init = 'pca'\n",
        "\n",
        "    if inputdist == 'distance' and init == 'pca':\n",
        "        raise ValueError(\"Cannot use init == 'pca' when inputdist == 'distance'\")\n",
        "\n",
        "    if np.count_nonzero(np.diagonal(D)) > 0:\n",
        "        raise ValueError(\"The diagonal of the dissimilarity matrix must be zero\")\n",
        "\n",
        "    # Remaining initialisation\n",
        "    N = x.shape[0]\n",
        "    scale = 0.5 / D.sum()\n",
        "    D = D + np.eye(N)     \n",
        "\n",
        "    if np.count_nonzero(D<=0) > 0:\n",
        "        raise ValueError(\"Off-diagonal dissimilarities must be strictly positive\")   \n",
        "\n",
        "    Dinv = 1 / D\n",
        "    if init == 'pca':\n",
        "        [UU,DD,_] = np.linalg.svd(x)\n",
        "        y = UU[:,:n]*DD[:n] \n",
        "    elif init == 'cmdscale':\n",
        "        from cmdscale import cmdscale\n",
        "        y,e = cmdscale(D)\n",
        "        y = y[:,:n]\n",
        "    else:\n",
        "        y = np.random.normal(0.0,1.0,[N,n])\n",
        "    one = np.ones([N,n])\n",
        "    d = cdist(y,y) + np.eye(N)\n",
        "    dinv = 1. / d\n",
        "    delta = D-d \n",
        "    E = ((delta**2)*Dinv).sum() \n",
        "\n",
        "    # Get on with it\n",
        "    for i in range(maxiter):\n",
        "        # Compute gradient, Hessian and search direction (note it is actually\n",
        "        # 1/4 of the gradient and Hessian, but the step size is just the ratio\n",
        "        # of the gradient and the diagonal of the Hessian so it doesn't\n",
        "        # matter).\n",
        "        delta = dinv - Dinv\n",
        "        deltaone = np.dot(delta,one)\n",
        "        g = np.dot(delta,y) - (y * deltaone)\n",
        "        dinv3 = dinv ** 3\n",
        "        y2 = y ** 2\n",
        "        H = np.dot(dinv3,y2) - deltaone - np.dot(2,y) * np.dot(dinv3,y) + y2 * np.dot(dinv3,one)\n",
        "        s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))\n",
        "        y_old    = y\n",
        "\n",
        "        # Use step-halving procedure to ensure progress is made\n",
        "        for j in range(maxhalves):\n",
        "            s_reshape = np.reshape(s, (-1,n),order='F')\n",
        "            y = y_old + s_reshape\n",
        "            d = cdist(y, y) + np.eye(N)\n",
        "            dinv = 1 / d\n",
        "            delta = D - d\n",
        "            E_new = ((delta**2)*Dinv).sum()\n",
        "            if E_new < E:\n",
        "                break\n",
        "            else:\n",
        "                s = 0.5*s\n",
        "\n",
        "        # Bomb out if too many halving steps are required\n",
        "        if j == maxhalves-1:\n",
        "            print('Warning: maxhalves exceeded. Sammon mapping may not converge...')\n",
        "\n",
        "        # Evaluate termination criterion\n",
        "        if abs((E - E_new) / E) < tolfun:\n",
        "            if display:\n",
        "                print('TolFun exceeded: Optimisation terminated')\n",
        "            break\n",
        "\n",
        "        # Report progress\n",
        "        E = E_new\n",
        "        if display > 1:\n",
        "            print('epoch = %d : E = %12.10f'% (i+1, E * scale))\n",
        "\n",
        "    if i == maxiter-1:\n",
        "        print('Warning: maxiter exceeded. Sammon mapping may not have converged...')\n",
        "\n",
        "    # Fiddle stress to match the original Sammon paper\n",
        "    E = E * scale\n",
        "    \n",
        "    return [y,E]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJV_WbKK6fzB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import random_projection\n",
        "from sklearn.manifold import Isomap\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import KernelPCA\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn import manifold\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "#create new dataframes. they will contain principal components extracted from different dimensionality reduction techniques\n",
        "#df_dimredu contains components extracted from outlierness scores\n",
        "#df_dataredu contains components extracted from original data\n",
        "\n",
        "df_dimredu = pd.DataFrame()\n",
        "df_dataredu = pd.DataFrame()\n",
        "df_binredu = pd.DataFrame()\n",
        "\n",
        "def dim_redu_methods(data, scores_df, binary_scores_df):\n",
        "  pca = PCA(n_components=2)\n",
        "  out_pca = pd.DataFrame()\n",
        "  out_pca_scores = pd.DataFrame()\n",
        "  out_pca_bin = pd.DataFrame()\n",
        "  try:\n",
        "    pca.fit(data)\n",
        "    out_pca = pd.DataFrame(pca.transform(data), index=data.index)\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 1')\n",
        "\n",
        "  try:\n",
        "    pca.fit(scores_df)\n",
        "    out_pca_scores = pd.DataFrame(pca.transform(scores_df), index=scores_df.index)\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 2')\n",
        "\n",
        "  try:\n",
        "    pca.fit(binary_scores_df)\n",
        "    out_pca_bin = pd.DataFrame(pca.transform(binary_scores_df), index=binary_scores_df.index)\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 3')\n",
        "\n",
        "  try:\n",
        "    df_dataredu['pca1_data'] = out_pca[0]\n",
        "    df_dataredu['pca2_data'] = out_pca[1]\n",
        "    df_dimredu['pca1_scores'] = out_pca_scores[0]\n",
        "    df_dimredu['pca2_scores'] = out_pca_scores[1]\n",
        "    df_binredu['pca1_binary'] = out_pca_bin[0]\n",
        "    df_binredu['pca2_binary'] = out_pca_bin[1]\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config loading')\n",
        "\n",
        "  rsp = random_projection.GaussianRandomProjection(n_components=2)\n",
        "  try:\n",
        "    ran_proj = rsp.fit_transform(scores_df)\n",
        "    df_dimredu['sub_proj1_scores'] = ran_proj[:,0]\n",
        "    df_dimredu['sub_proj2_scores'] = ran_proj[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Random Projection Config scores')\n",
        "\n",
        "  try:  \n",
        "    ran_proj_data = rsp.fit_transform(data)\n",
        "    df_dataredu['sub_proj1_data'] = ran_proj_data[:,0]\n",
        "    df_dataredu['sub_proj2_data'] = ran_proj_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Random Projection Config data')\n",
        "\n",
        "  try:\n",
        "    ran_proj_bin = rsp.fit_transform(binary_scores_df)\n",
        "    df_binredu['sub_proj1_binary'] = ran_proj_bin[:,0]\n",
        "    df_binredu['sub_proj2_binary'] = ran_proj_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Random Projection Config binary')\n",
        "\n",
        "  iso = Isomap(n_components=2)\n",
        "\n",
        "  try:\n",
        "    iso_proj = iso.fit_transform(scores_df)\n",
        "    df_dimredu['iso_map_1_scores'] = iso_proj[:,0]\n",
        "    df_dimredu['iso_map_2_scores'] = iso_proj[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Map Config scores')\n",
        "\n",
        "  try:\n",
        "    iso_proj_data = iso.fit_transform(data)\n",
        "    df_dataredu['iso_map_1_data'] = iso_proj_data[:,0]\n",
        "    df_dataredu['iso_map_2_data'] = iso_proj_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Map Config data')\n",
        "\n",
        "  try:  \n",
        "    iso_proj_bin = iso.fit_transform(binary_scores_df)\n",
        "    df_binredu['iso_map_1_binary'] = iso_proj_bin[:,0]\n",
        "    df_binredu['iso_map_2_binary'] = iso_proj_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Map Config binary')\n",
        "\n",
        "  tsne = TSNE(n_components=2)\n",
        "\n",
        "  try:\n",
        "    sne_proj = tsne.fit_transform(scores_df)\n",
        "    df_dimredu['sne_1_scores'] = sne_proj[:,0]\n",
        "    df_dimredu['sne_2_scores'] = sne_proj[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> TSNE Config scores')\n",
        "\n",
        "  try:  \n",
        "    sne_proj_data = tsne.fit_transform(data)\n",
        "    df_dataredu['sne_1_data'] = sne_proj_data[:,0]\n",
        "    df_dataredu['sne_2_data'] = sne_proj_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> TSNE Config data')\n",
        "\n",
        "  try:\n",
        "    sne_proj_bin = tsne.fit_transform(binary_scores_df)\n",
        "    df_binredu['sne_1_binary'] = sne_proj_bin[:,0]\n",
        "    df_binredu['sne_2_binary'] = sne_proj_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> TSNE Config binary')\n",
        "\n",
        "  clf = LinearDiscriminantAnalysis()\n",
        "\n",
        "  try:\n",
        "    clf.fit(scores_df, target)\n",
        "    lda_proj = clf.transform(scores_df)\n",
        "    df_dimredu['lda_1_scores_0'] = lda_proj[0:lda_proj.shape[0], 0]\n",
        "    df_dimredu['lda_1_scores_1'] = lda_proj[0:lda_proj.shape[0], 1]\n",
        "    df_dimredu['lda_1_scores_2'] = lda_proj[0:lda_proj.shape[0], 2]\n",
        "    df_dimredu['lda_1_scores_3'] = lda_proj[0:lda_proj.shape[0], 3]\n",
        "    df_dimredu['lda_1_scores_4'] = lda_proj[0:lda_proj.shape[0], 4]\n",
        "    df_dimredu['lda_1_scores_5'] = lda_proj[0:lda_proj.shape[0], 5]\n",
        "    df_dimredu['lda_1_scores_6'] = lda_proj[0:lda_proj.shape[0], 6]\n",
        "    df_dimredu['lda_1_scores_7'] = lda_proj[0:lda_proj.shape[0], 7]\n",
        "    df_dimredu['lda_1_scores_8'] = lda_proj[0:lda_proj.shape[0], 8]\n",
        "    df_dimredu['lda_1_scores_9'] = lda_proj[0:lda_proj.shape[0], 9]\n",
        "    df_dimredu['lda_1_scores_10'] = lda_proj[0:lda_proj.shape[0], 10]\n",
        "  except:\n",
        "    print('Exception Raised --> Linear Discriminant Analysis (classes exceeded)')\n",
        "\n",
        "  try:\n",
        "    clf.fit(data, target)\n",
        "    lda_proj_data = clf.transform(data)\n",
        "    df_dataredu['lda_1_data_0'] = lda_proj_data[0:lda_proj_data.shape[0], 0]\n",
        "    df_dataredu['lda_1_data_1'] = lda_proj_data[0:lda_proj_data.shape[0], 1]\n",
        "    df_dataredu['lda_1_data_2'] = lda_proj_data[0:lda_proj_data.shape[0], 2]\n",
        "    df_dataredu['lda_1_data_3'] = lda_proj_data[0:lda_proj_data.shape[0], 3]\n",
        "    df_dataredu['lda_1_data_4'] = lda_proj_data[0:lda_proj_data.shape[0], 4]\n",
        "    df_dataredu['lda_1_data_5'] = lda_proj_data[0:lda_proj_data.shape[0], 5]\n",
        "    df_dataredu['lda_1_data_6'] = lda_proj_data[0:lda_proj_data.shape[0], 6]\n",
        "    df_dataredu['lda_1_data_7'] = lda_proj_data[0:lda_proj_data.shape[0], 7]\n",
        "    df_dataredu['lda_1_data_8'] = lda_proj_data[0:lda_proj_data.shape[0], 8]\n",
        "    df_dataredu['lda_1_data_9'] = lda_proj_data[0:lda_proj_data.shape[0], 9]\n",
        "    df_dataredu['lda_1_data_10'] = lda_proj_data[0:lda_proj_data.shape[0], 10]\n",
        "  except:\n",
        "    print('Exception Raised --> Linear Discriminant Analysis Config (classes exceeded)')\n",
        "\n",
        "  try:\n",
        "    clf.fit(binary_scores_df, target)\n",
        "    lda_proj_bin = clf.transform(binary_scores_df) \n",
        "    df_binredu['lda_1_binary_0'] = lda_proj_bin[0:lda_proj_bin.shape[0], 0]\n",
        "    df_binredu['lda_1_binary_1'] = lda_proj_bin[0:lda_proj_bin.shape[0], 1]\n",
        "    df_binredu['lda_1_binary_2'] = lda_proj_bin[0:lda_proj_bin.shape[0], 2]\n",
        "    df_binredu['lda_1_binary_3'] = lda_proj_bin[0:lda_proj_bin.shape[0], 3]\n",
        "    df_binredu['lda_1_binary_4'] = lda_proj_bin[0:lda_proj_bin.shape[0], 4]\n",
        "    df_binredu['lda_1_binary_5'] = lda_proj_bin[0:lda_proj_bin.shape[0], 5]\n",
        "    df_binredu['lda_1_binary_6'] = lda_proj_bin[0:lda_proj_bin.shape[0], 6]\n",
        "    df_binredu['lda_1_binary_7'] = lda_proj_bin[0:lda_proj_bin.shape[0], 7]\n",
        "    df_binredu['lda_1_binary_8'] = lda_proj_bin[0:lda_proj_bin.shape[0], 8]\n",
        "    df_binredu['lda_1_binary_9'] = lda_proj_bin[0:lda_proj_bin.shape[0], 9]\n",
        "    df_binredu['lda_1_binary_10'] = lda_proj_bin[0:lda_proj_bin.shape[0], 10]\n",
        "  except:\n",
        "    print('Exception Raised --> Linear Discriminant Analysis Config (classes exceeded)')\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='rbf', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['rbf_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['rbf_pca_2_scores'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 1')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['rbf_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['rbf_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 1')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['rbf_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['rbf_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 1')\n",
        "\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='cosine', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['cosine_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['cosine_pca_2_scores'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 2')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['cosine_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['cosine_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 2')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['cosine_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['cosine_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 2')\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='sigmoid', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['sigmoid_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['sigmoid_pca_2_scores'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 3')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['sigmoid_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['sigmoid_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 3')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['sigmoid_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['sigmoid_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 3')\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='poly', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['poly_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['poly_pca_2_scores_'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 4')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['poly_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['poly_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 4')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['poly_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['poly_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 4')\n",
        "\n",
        "  #convert two scores in numeric, to perform sammon function\n",
        "  if 'pynomaly_loop_original' in scores_df.columns:\n",
        "    scores_df[\"pynomaly_loop_original\"] = pd.to_numeric(scores_df[\"pynomaly_loop_original\"])\n",
        "  #scores_df[\"dbscan_scores_original\"] = pd.to_numeric(scores_df[\"dbscan_scores_original\"])\n",
        "\n",
        "  try:\n",
        "    # By default, sammon returns a 2-dim array and the error E\n",
        "    [y, E] = sammon(data, maxiter=20, n=2)\n",
        "    [y2, E2] = sammon(scores_df, maxiter=20, n=2)\n",
        "\n",
        "    df_dataredu['sammon_1_data'] = y[:,0]\n",
        "    df_dataredu['sammon_2_data'] = y[:,1]\n",
        "    df_dimredu['sammon_1_scores'] = y2[:,0]\n",
        "    df_dimredu['sammon_2_scores'] = y2[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Sammon Mapping Config')\n",
        "\n",
        "  try:\n",
        "    Axes3D\n",
        "    n_neighbors = 100\n",
        "    n_components = 2\n",
        "    # Set-up manifold methods\n",
        "    LLE = partial(manifold.LocallyLinearEmbedding, n_neighbors=n_neighbors, n_components=n_components, eigen_solver=\"auto\")\n",
        "    methods = OrderedDict()\n",
        "    methods[\"LLE\"] = LLE(method=\"standard\")\n",
        "    methods[\"Hessian LLE\"] = LLE(method=\"hessian\", eigen_solver='dense')\n",
        "    methods[\"Modified LLE\"] = LLE(method=\"modified\", eigen_solver='dense')\n",
        "    methods[\"MDS\"] = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
        "    methods[\"SE\"] = manifold.SpectralEmbedding(n_components=n_components, n_neighbors=n_neighbors)\n",
        "  except:\n",
        "    print('Exception Raised -> MainFold Methods Inizialization')\n",
        "  try:\n",
        "    for i, (label, method) in enumerate(methods.items()):\n",
        "      Y = method.fit_transform(scores_df)\n",
        "      Y2 = method.fit_transform(data)\n",
        "      str1 = label+\"_1\"\n",
        "      str2 = label+\"_2\"  \n",
        "      \n",
        "      if(label!='Modified LLE'):\n",
        "        Y3 = method.fit_transform(binary_scores_df)\n",
        "        df_binredu[str1+\"_binary\"] = Y3[:,0]\n",
        "        df_binredu[str2+\"_binary\"] = Y3[:,1]      \n",
        "      \n",
        "      df_dimredu[str1+\"_scores\"] = Y[:,0]\n",
        "      df_dimredu[str2+\"_scores\"] = Y[:,1]\n",
        "      df_dataredu[str1+\"_data\"] = Y2[:,0]\n",
        "      df_dataredu[str2+\"_data\"] = Y2[:,1]\n",
        "      print(\"%s Completed\" % (label))\n",
        "  except:\n",
        "    print('Exception Raised --> MainFold Methods Calculus')\n",
        "\n",
        "  try:\n",
        "    # Fixed dimensions\n",
        "    input_dim = data.shape[1]\n",
        "    encoding_dim = 2\n",
        "    # Number of neurons in each Layer [8, 6, 4, 3, ...] of encoders\n",
        "    input_layer = Input(shape=(input_dim, ))\n",
        "    encoder_layer_1 = Dense(18, activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "    encoder_layer_2 = Dense(9, activation=\"tanh\")(encoder_layer_1)\n",
        "    encoder_layer_3 = Dense(7, activation=\"tanh\")(encoder_layer_2)\n",
        "    encoder_layer_4 = Dense(5, activation=\"relu\")(encoder_layer_3)\n",
        "    encoder_layer_5 = Dense(3, activation=\"relu\")(encoder_layer_4)\n",
        "    encoder_layer_6 = Dense(encoding_dim, activation=\"sigmoid\")(encoder_layer_5)\n",
        "\n",
        "    # Crear encoder model\n",
        "    encoder = Model(inputs=input_layer, outputs=encoder_layer_6)\n",
        "    # Use the model to predict the factors which sum up the information of interest rates.\n",
        "    encoded_data = pd.DataFrame(encoder.predict(data))\n",
        "    encoded_data.columns = ['factor_1', 'factor_2']\n",
        "\n",
        "    # Fixed dimensions\n",
        "    input_dim = scores_df.shape[1]\n",
        "    encoding_dim = 2\n",
        "    # Number of neurons in each Layer [8, 6, 4, 3, ...] of encoders\n",
        "    input_layer = Input(shape=(input_dim, ))\n",
        "    encoder_layer_1 = Dense(18, activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "    encoder_layer_2 = Dense(9, activation=\"relu\")(encoder_layer_1)\n",
        "    encoder_layer_3 = Dense(7, activation=\"relu\")(encoder_layer_2)\n",
        "    encoder_layer_4 = Dense(5, activation=\"relu\")(encoder_layer_3)\n",
        "    encoder_layer_5 = Dense(3, activation=\"relu\")(encoder_layer_4)\n",
        "    encoder_layer_6 = Dense(encoding_dim, activation=\"sigmoid\")(encoder_layer_5)\n",
        "\n",
        "    # Crear encoder model\n",
        "    encoder = Model(inputs=input_layer, outputs=encoder_layer_6)\n",
        "    # Use the model to predict the factors which sum up the information of interest rates.\n",
        "    encoded_scores = pd.DataFrame(encoder.predict(scores_df))\n",
        "    encoded_scores.columns = ['factor_1', 'factor_2']\n",
        "\n",
        "    # Fixed dimensions\n",
        "    input_dim = binary_scores_df.shape[1]\n",
        "    encoding_dim = 2\n",
        "    # Number of neurons in each Layer [8, 6, 4, 3, ...] of encoders\n",
        "    input_layer = Input(shape=(input_dim, ))\n",
        "    encoder_layer_1 = Dense(18, activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "    encoder_layer_2 = Dense(9, activation=\"relu\")(encoder_layer_1)\n",
        "    encoder_layer_3 = Dense(7, activation=\"relu\")(encoder_layer_2)\n",
        "    encoder_layer_4 = Dense(5, activation=\"relu\")(encoder_layer_3)\n",
        "    encoder_layer_5 = Dense(3, activation=\"relu\")(encoder_layer_4)\n",
        "    encoder_layer_6 = Dense(encoding_dim, activation=\"sigmoid\")(encoder_layer_5)\n",
        "\n",
        "    # Crear encoder model\n",
        "    encoder = Model(inputs=input_layer, outputs=encoder_layer_6)\n",
        "    # Use the model to predict the factors which sum up the information of interest rates.\n",
        "    encoded_bin = pd.DataFrame(encoder.predict(binary_scores_df))\n",
        "    encoded_bin.columns = ['factor_1', 'factor_2']\n",
        "\n",
        "    df_dataredu['autoencoder_1_data'] = encoded_data['factor_1']\n",
        "    df_dataredu['autoencoder_2_data'] = encoded_data['factor_2']\n",
        "    df_dimredu['autoencoder_1_scores'] = encoded_scores['factor_1']\n",
        "    df_dimredu['autoencoder_2_scores'] = encoded_scores['factor_2']\n",
        "    df_binredu['autoencoder_1_binary'] = encoded_bin['factor_1']\n",
        "    df_binredu['autoencoder_2_binary'] = encoded_bin['factor_2']\n",
        "  except:\n",
        "    print('Exception Raised --> AutoEncoder Config')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H9dBtOaOpyP"
      },
      "source": [
        "#APPLY FEATURE EXTRACTION PIPELINE ON ORIGINAL DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHmRv0acOuJ_"
      },
      "outputs": [],
      "source": [
        "def extract_outlierness_features(data, pynomaly=True, sklearn=True, pyod=True, network=True):\n",
        "  if(pynomaly==True):\n",
        "    pynomaly_methods(data, scores_df, binary_scores_df)\n",
        "  if(sklearn==True):\n",
        "    sklearn_methods(data, scores_df, binary_scores_df)\n",
        "  if(pyod==True):\n",
        "    pyod_methods(data, scores_df, binary_scores_df)\n",
        "  if(network==True):\n",
        "    network_methods(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1UTkoUYKOi3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print('Outlierness Scores Extraction: \\n')\n",
        "extract_outlierness_features(data, pynomaly=True,sklearn=True,pyod=True,network=False)\n",
        "\n",
        "#normalize outlierness scores\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "scores_df = pd.DataFrame(scaler.fit_transform(scores_df), columns=scores_df.columns)\n",
        "\n",
        "print('\\nNull Values in Outlierness Scores DataSets:')\n",
        "print('Scores_df: ')\n",
        "scores_df.loc[:, scores_df.isna().any()]\n",
        "scores_df.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "print('--- --- ---')\n",
        "print('Binary_Scores_df: ')\n",
        "binary_scores_df.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "binary_scores_df.loc[:, binary_scores_df.isna().any()]\n",
        "print('--- --- ---')\n",
        "\n",
        "#save outlierness numeric and binary scores to .csv\n",
        "scores_df.to_csv(directory + \"outlierness_scores.csv\")\n",
        "binary_scores_df.to_csv(directory + \"binary_scores.csv\")\n",
        "\n",
        "#apply dimensionality reduction methods on original data, numeric and binary outlierness scores\n",
        "print('\\n--- --- --- --- ---\\nDimensionality Reduction Features Extraction: ')\n",
        "dim_redu_methods(data, scores_df, binary_scores_df)\n",
        "\n",
        "print('\\nNull Values in Dimensionality Reduction DataSets:')\n",
        "df_dimredu.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "print(df_dimredu.isnull().sum())\n",
        "print('--- --- ---')\n",
        "df_dataredu.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "print(df_dataredu.isnull().sum())\n",
        "print('--- --- ---')\n",
        "df_binredu.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "print(df_binredu.isnull().sum())\n",
        "print('--- --- ---')\n",
        "\n",
        "#normalize calculated principal components\n",
        "scaler = RobustScaler()\n",
        "df_dimredu = pd.DataFrame(scaler.fit_transform(df_dimredu), columns=df_dimredu.columns)\n",
        "df_dataredu = pd.DataFrame(scaler.fit_transform(df_dataredu), columns=df_dataredu.columns)\n",
        "df_binredu = pd.DataFrame(scaler.fit_transform(df_binredu), columns=df_binredu.columns)\n",
        "\n",
        "end = time.time()\n",
        "#save first feature extraction phase time ellapsed\n",
        "print(\"Support Features Extraction Time: %.8s seconds\" % (end - start_time))\n",
        "\n",
        "#save dimensionality reduction (applied on original data, binary and numeric outlierness scores) to .csv\n",
        "df_dimredu.to_csv(directory + \"dim_redu_scores.csv\")\n",
        "df_dataredu.to_csv(directory + \"dim_redu_original_data.csv\")\n",
        "df_binredu.to_csv(directory + \"dim_redu_binary_scores.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-1PW4MHDATY"
      },
      "source": [
        "#OUTLIERNESS SCORES EXTRACTION ON PRINCIPAL COMPONENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJJZzXZiDTJg"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(directory+'dim_redu_original_data.csv', delimiter=',') #load data\n",
        "data.drop('Unnamed: 0', inplace=True, axis=1)\n",
        "\n",
        "original = pd.read_csv(directory+dataname, delimiter=',') #load data\n",
        "original.drop('Unnamed: 0', inplace=True, axis=1)\n",
        "target = original['class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-5r-qRIDATY"
      },
      "source": [
        "##pynomaly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfi_KgeL0x1n"
      },
      "outputs": [],
      "source": [
        "scores_df = pd.DataFrame()\n",
        "binary_scores_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YbNuMb2Hzil"
      },
      "outputs": [],
      "source": [
        "def pynomaly_methods(data, scores_df, binary_scores_df):\n",
        "  try:\n",
        "    m = loop.LocalOutlierProbability(data, progress_bar=True).fit()\n",
        "    scores = m.local_outlier_probabilities\n",
        "\n",
        "    scores_df = pd.DataFrame(scores, columns = ['pynomaly_loop_dim_redu'])\n",
        "    binary_scores_df = pd.DataFrame(scores, columns = ['pynomaly_loop_dim_redu_binary'])\n",
        "    binary_scores_df['pynomaly_loop_dim_redu_binary'] = np.where(binary_scores_df['pynomaly_loop_dim_redu_binary']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> LOP Config')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps01_sam10_nei10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam10_nei10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam10_nei10_e1'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam10_nei10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 1')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps01_sam20_nei10_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam20_nei10_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam20_nei10_e2'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam20_nei10_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 2')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, n_neighbors=20, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps01_sam20_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam20_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam20_nei20_e2'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam20_nei20_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 3')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps01_sam50_nei10_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei10_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei10_e3'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei10_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 4')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=20, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps01_sam50_nei20_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei20_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei20_e3'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei20_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 5')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=50, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps01_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei50_e3'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps01_sam50_nei50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 6')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps03_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam10_e1'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 7')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps03_sam20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam20_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam20_e1'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam20_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 8')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2,  cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps03_sam50_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e2'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 9')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3,cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e3'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 10')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e3'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps03_sam50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 11')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.5, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1,cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps05_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam10_e1'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 12')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.5, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps05_sam20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam20_e2'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam20_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 13')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.5, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps05_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam50_e3'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps05_sam50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 14')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.9, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps09_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam10_e1'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 15')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.9, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps09_sam20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam20_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam20_e1'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam20_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 16')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.9, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps09_sam50_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_e1'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_e1'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 17')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.9, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps09_sam50_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_nei20_e2'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_nei20_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 18')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.9, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['dbscan_scores_dim_redu_eps09_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_nei50_e3'] = np.where(binary_scores_df['dbscan_scores_dim_redu_binary_eps09_sam50_nei50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised -> DBSCAN Config 19')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bOjTQ72DATZ"
      },
      "source": [
        "##sklearn algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4ZpafaA1IPm"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "def sklearn_methods(data, scores_df, binary_scores_df):\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.001)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_dim_redu_cont0.001'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_dim_redu_cont0.001'] = maha\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.001'] = pred\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.001'] = np.where(binary_scores_df['elliptic_env_dim_redu_binary_cont0.001']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 1')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.01)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_dim_redu_cont0.01'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_dim_redu_cont0.01'] = maha\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.01'] = pred\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.01'] = np.where(binary_scores_df['elliptic_env_dim_redu_binary_cont0.01']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 2')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.1)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_dim_redu_cont0.1'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_dim_redu_cont0.1'] = maha\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.1'] = pred\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.1'] = np.where(binary_scores_df['elliptic_env_dim_redu_binary_cont0.1']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 3')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.2)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_dim_redu_cont0.2'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_dim_redu_cont0.2'] = maha\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.2'] = pred\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.2'] = np.where(binary_scores_df['elliptic_env_dim_redu_binary_cont0.2']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 4')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.5)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['elliptic_decfunc_dim_redu_cont0.5'] = dec_func\n",
        "    scores_df['elliptic_mahalanobis_dim_redu_cont0.5'] = maha\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.5'] = pred\n",
        "    binary_scores_df['elliptic_env_dim_redu_binary_cont0.5'] = np.where(binary_scores_df['elliptic_env_dim_redu_binary_cont0.5']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 5')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.001, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_dim_redu_cont0.001'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.001'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.001'] = np.where(binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.001']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Isolation Forest Config 1')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.01, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_dim_redu_cont0.01'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.01'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.01'] = np.where(binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.01']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Isolation Forest Config 2')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.1, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_dim_redu_cont0.1'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.1'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.1'] = np.where(binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.1']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Isolation Forest Config 3')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.2, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_dim_redu_cont0.2'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.2'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.2'] = np.where(binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.2']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Isolation Forest Config 4')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.5, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['iso_forest_paper_score_dim_redu_cont0.5'] = original_paper_score\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.5'] = pred\n",
        "    binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.5'] = np.where(binary_scores_df['iso_forest_paper_score_dim_redu_binary_cont0.5']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Isolation Forest Config 5')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=10, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['lof_score_dim_redu_mink_nei10'] = lof_score\n",
        "    binary_scores_df['lof_score_dim_redu_binary_mink_nei10'] = pred\n",
        "    binary_scores_df['lof_score_dim_redu_binary_mink_nei10'] = np.where(binary_scores_df['lof_score_dim_redu_binary_mink_nei10']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 1')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=20, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['lof_score_dim_redu_mink_nei20'] = lof_score\n",
        "    binary_scores_df['lof_score_dim_redu_binary_mink_nei20'] = pred\n",
        "    binary_scores_df['lof_score_dim_redu_binary_mink_nei20'] = np.where(binary_scores_df['lof_score_dim_redu_binary_mink_nei20']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 2')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=50, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['lof_score_dim_redu_mink_nei50'] = lof_score\n",
        "    binary_scores_df['lof_score_dim_redu_binary_mink_nei50'] = pred\n",
        "    binary_scores_df['lof_score_dim_redu_binary_mink_nei50'] = np.where(binary_scores_df['lof_score_dim_redu_binary_mink_nei50']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 3')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.001, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_dim_redu_linear_nu0.001'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.001'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.001'] = np.where(binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.001']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> OneClass SVM Config 1')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.01, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_dim_redu_linear_nu0.01'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.01'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.01'] = np.where(binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.01']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> OneClass SVM Config 2')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.1, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_dim_redu_linear_nu0.1'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.1'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.1'] = np.where(binary_scores_df['oneclass_SVM_dim_redu_binary_linear_nu0.1']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> OneClass SVM Config 3')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.001)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_dim_redu_rbf_nu0.001'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.001'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.001'] = np.where(binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.001']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> OneClass SVM Config 4')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.01)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_dim_redu_rbf_nu0.01'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.01'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.01'] = np.where(binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.01']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> OneClass SVM Config 5')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.1)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['oneclass_SVM_dim_redu_rbf_nu0.1'] = ocsvm_score\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.1'] = pred\n",
        "  #   binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.1'] = np.where(binary_scores_df['oneclass_SVM_dim_redu_binary_rbf_nu0.1']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> OneClass SVM Config 6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrEhovdYDATZ"
      },
      "source": [
        "##pyod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HJLvDT01xUl"
      },
      "outputs": [],
      "source": [
        "from pyod.models.copod import COPOD\n",
        "from pyod.models.suod import SUOD\n",
        "from pyod.models.loda import LODA\n",
        "from pyod.models.feature_bagging import FeatureBagging\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.cof import COF\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.mcd import MCD\n",
        "from pyod.models.pca import PCA\n",
        "from pyod.models.ecod import ECOD\n",
        "from pyod.models.sos import SOS\n",
        "\n",
        "def pyod_methods(data, scores_df, binary_scores_df):\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_dim_redu_cont0.001'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COPOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_dim_redu_cont0.01'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COPOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_dim_redu_cont0.1'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COPOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_dim_redu_cont0.2'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COPOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['pyod_copod_dim_redu_cont0.5'] = pyod_copod\n",
        "    binary_scores_df['pyod_copod_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COPOD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_dim_redu_cont0.001'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> ECOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_dim_redu_cont0.01'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> ECOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_dim_redu_cont0.1'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> ECOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_dim_redu_cont0.2'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> ECOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['pyod_ecod_dim_redu_cont0.5'] = pyod_ecod\n",
        "    binary_scores_df['pyod_ecod_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> ECOD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_dim_redu_cont0.001'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOS Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_dim_redu_cont0.01'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOS Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_dim_redu_cont0.1'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOS Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_dim_redu_cont0.2'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOS Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['pyod_sos_dim_redu_cont0.5'] = pyod_sos\n",
        "    binary_scores_df['pyod_sos_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOS Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.001, whiten=False)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.001_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.001_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.01, whiten=False)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.01_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.01_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.1, whiten=False)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.1_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.1_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.2, whiten=False)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.2_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.2_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.5, whiten=False)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.5_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.5_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.001, whiten=True)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.001_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.001_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.01, whiten=True)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.01_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.01_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 7')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.1, whiten=True)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.1_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.1_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.2, whiten=True)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.2_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.2_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.5, whiten=True)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['pyod_pca_dim_redu_cont0.5_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['pyod_pca_dim_redu_binary_cont0.5_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 10')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_dim_redu_cont0.001'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MCD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_dim_redu_cont0.01'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MCD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_dim_redu_cont0.1'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MCD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_dim_redu_cont0.2'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MCD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['pyod_mcd_dim_redu_cont0.5'] = pyod_mcd\n",
        "    binary_scores_df['pyod_mcd_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MCD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.001_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.001_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.01_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.01_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.1_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.1_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.2_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.2_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.5_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.5_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.001_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.001_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.001_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.001_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 7')\n",
        "\n",
        "  try:  \n",
        "    clf = OCSVM(contamination=0.001, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.001_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.001_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.01_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.001_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.01_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.001_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 10')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.01_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.001_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 11')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.1_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.1_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 12')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.1_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.1_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 13')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.1_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.1_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 14')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.2_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.2_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 15')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.2_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.2_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 16')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.2_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.2_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 17')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.5_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.5_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 18')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.5_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.5_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 19')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['pyod_ocsvm_dim_redu_cont0.5_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['pyod_ocsvm_dim_redu_binary_cont0.5_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> OCSVM Config 20')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.001_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.001_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.01_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.01_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.1_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.1_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.2_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.2_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.5_nei10'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.5_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.001_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.001_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.01_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.01_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 7')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.1_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.1_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.2_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.2_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.5_nei20'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.5_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 10')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.001_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.001_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 11')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.01_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.01_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 12')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.1_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.1_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 13')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.2_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.2_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 14')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['pyod_cof_dim_redu_cont0.5_nei50'] = pyod_cof\n",
        "    binary_scores_df['pyod_cof_dim_redu_binary_cont0.5_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> COF Config 15')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_dim_redu_cont0.001'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> CBLOF Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_dim_redu_cont0.01'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> CBLOF Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_dim_redu_cont0.1'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> CBLOF Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_dim_redu_cont0.2'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> CBLOF Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['pyod_cblof_dim_redu_cont0.5'] = pyod_cblof\n",
        "    binary_scores_df['pyod_cblof_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> CBLOF Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_dim_redu_cont0.001'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> HBOS Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_dim_redu_cont0.01'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> HBOS Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_dim_redu_cont0.1'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> HBOS Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_dim_redu_cont0.2'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> HBOS Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['pyod_hbos_dim_redu_cont0.5'] = pyod_hbos\n",
        "    binary_scores_df['pyod_hbos_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> HBOS Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_dim_redu_cont0.001'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> KNN Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_dim_redu_cont0.01'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> KNN Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_dim_redu_cont0.1'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> KNN Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_dim_redu_cont0.2'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> KNN Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['pyod_knn_dim_redu_cont0.5'] = pyod_knn\n",
        "    binary_scores_df['pyod_knn_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> KNN Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_dim_redu_cont0.001'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> Feature Bagging Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_dim_redu_cont0.01'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> Feature Bagging Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_dim_redu_cont0.1'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> Feature Bagging Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_dim_redu_cont0.2'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> Feature Bagging Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['pyod_featbagg_dim_redu_cont0.5'] = pyod_featbagg\n",
        "    binary_scores_df['pyod_featbagg_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> Feature Bagging Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_dim_redu_cont0.001'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> LODA Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_dim_redu_cont0.01'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> LODA Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_dim_redu_cont0.1'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> LODA Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_dim_redu_cont0.2'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> LODA Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['pyod_loda_dim_redu_cont0.5'] = pyod_loda\n",
        "    binary_scores_df['pyod_loda_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> LODA Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_dim_redu_cont0.001'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SUOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_dim_redu_cont0.01'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SUOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_dim_redu_cont0.1'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SUOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_dim_redu_cont0.2'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SUOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['pyod_suod_dim_redu_cont0.5'] = pyod_suod\n",
        "    binary_scores_df['pyod_suod_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SUOD Config 5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKDpXqb0DATb"
      },
      "source": [
        "network methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkyr2iAF3Lol"
      },
      "outputs": [],
      "source": [
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "from pyod.models.deep_svdd import DeepSVDD\n",
        "from pyod.models.mo_gaal import MO_GAAL\n",
        "import pyod.models.deep_svdd\n",
        "from pyod.models.so_gaal import SO_GAAL\n",
        "from pyod.models.vae import VAE\n",
        "\n",
        "def network_methods(data, scores_df, binary_scores_df):\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_dim_redu_cont0.001'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> AutoEncoder Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_dim_redu_cont0.01'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> AutoEncoder Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_dim_redu_cont0.1'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> AutoEncoder Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_dim_redu_cont0.2'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> AutoEncoder Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['pyod_encoder_dim_redu_cont0.5'] = pyod_encoder\n",
        "    binary_scores_df['pyod_encoder_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> AutoEncoder Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_dim_redu_cont0.001'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> VAE Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_dim_redu_cont0.01'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> VAE Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_dim_redu_cont0.1'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> VAE Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_dim_redu_cont0.2'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> VAE Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['pyod_vae_dim_redu_cont0.5'] = pyod_vae\n",
        "    binary_scores_df['pyod_vae_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> VAE Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.001, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.001_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.001_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.01, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.01_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.01_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.1_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.1_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.2, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.2_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.2_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.5, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.5_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.5_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.1_lrd0.01_lrg0.01_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.1_lrd0.01_lrg0.01_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.3 , lr_g=0.3 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.1_lrd0.3_lrg0.3_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.1_lrd0.3_lrg0.3_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 7')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.1_lrd0.01_lrg0.01_mom0.1'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.1_lrd0.01_lrg0.01_mom0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['pyod_sogaal_dim_redu_cont0.1_lrd0.01_lrg0.01_mom0.3'] = pyod_sogaal\n",
        "    binary_scores_df['pyod_sogaal_dim_redu_binary_cont0.1_lrd0.01_lrg0.01_mom0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> SOGAAL Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = pyod.models.deep_svdd.DeepSVDD(verbose=1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_dim_redu'] = pyod_svdd\n",
        "    binary_scores_df['pyod_svdd_dim_redu_binary'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> DEEP SVDD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_dim_redu_cont0.001'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MOGAAL Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_dim_redu_cont0.01'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MOGAAL Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_dim_redu_cont0.1'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MOGAAL Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_dim_redu_cont0.2'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MOGAAL Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['pyod_mogaal_dim_redu_cont0.5'] = pyod_mogaal\n",
        "    binary_scores_df['pyod_mogaal_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> MOGAAL Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_dim_redu_cont0.001'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_dim_redu_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> DEEPSVDD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_dim_redu_cont0.01'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_dim_redu_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> DEEPSVDD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_dim_redu_cont0.1'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_dim_redu_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> DEEPSVDD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_dim_redu_cont0.2'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_dim_redu_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> DEEPSVDD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['pyod_svdd_decfunc_dim_redu_cont0.5'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['pyod_svdd_decfunc_dim_redu_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised --> DEEPSVDD Config 6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0h5MIoF35Zs"
      },
      "source": [
        "#APPLY FEATURE EXTRACTION PIPELINE ON PRINCIPAL COMPONENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiElSDGG37nE"
      },
      "outputs": [],
      "source": [
        "def extract_outlierness_features(data, pynomaly=True, sklearn=True, pyod=True, network=False):\n",
        "  if(pynomaly==True):\n",
        "    pynomaly_methods(data, scores_df, binary_scores_df)\n",
        "  if(sklearn==True):\n",
        "    sklearn_methods(data, scores_df, binary_scores_df)\n",
        "  if(pyod==True):\n",
        "    pyod_methods(data, scores_df, binary_scores_df)\n",
        "  if(network==True):\n",
        "    network_methods(data, scores_df, binary_scores_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tffutDv4BN1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "import time\n",
        "\n",
        "print('Outlierness Scores from Principal Components Datasets: ')\n",
        "start_time = time.time()\n",
        "extract_outlierness_features(data, pynomaly=True, sklearn=True, pyod=True, network=False)\n",
        "end = time.time()\n",
        "\n",
        "#save first feature extraction phase time ellapsed\n",
        "print(\"Support Features on Principal Components Extraction Time: %.8s seconds\" % (end - start_time))\n",
        "print('\\nNull Values in Outlierness Scores DataSets:')\n",
        "print('Scores_df: ')\n",
        "scores_df.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "scores_df.loc[:, scores_df.isna().any()]\n",
        "print('--- --- ---')\n",
        "print('Binary_Scores_df: ')\n",
        "binary_scores_df.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "binary_scores_df.loc[:, binary_scores_df.isna().any()]\n",
        "print('--- --- ---')\n",
        "\n",
        "#normalize outlierness scores\n",
        "scaler = RobustScaler()\n",
        "scores_df = pd.DataFrame(scaler.fit_transform(scores_df), columns=scores_df.columns)\n",
        "\n",
        "scores_df.to_csv(directory + \"scores_principal_comp.csv\")\n",
        "binary_scores_df.to_csv(directory + \"binary_scores_principal_comp.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKjSFOGnDvyt"
      },
      "source": [
        "#OUTLIERNESS SCORES EXTRACTION ON OUTLIERNESS SCORES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrInPSL6DoGA"
      },
      "outputs": [],
      "source": [
        "dataname = 'outlierness_scores.csv'\n",
        "dataname2 = 'dim_redu_original_data.csv'\n",
        "\n",
        "data = pd.read_csv(directory+dataname, delimiter=',') #load outlierness scores on original data -> apply anomaly detection on it\n",
        "data.drop('Unnamed: 0', inplace=True, axis=1)\n",
        "\n",
        "data2 = pd.read_csv(directory+dataname2, delimiter=',') #load principal components on original data -> apply dimensionality reduction on it\n",
        "data2.drop('Unnamed: 0', inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9jnsMkKDvyt"
      },
      "source": [
        "##pynomaly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvkxWvmiDvyt"
      },
      "outputs": [],
      "source": [
        "scores_df = pd.DataFrame()\n",
        "binary_scores_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJNREI0hDvyt"
      },
      "outputs": [],
      "source": [
        "def pynomaly_methods(data, scores_df, binary_scores_df):\n",
        "  #no parameters to test\n",
        "  try:\n",
        "    m = loop.LocalOutlierProbability(data, progress_bar=True).fit()\n",
        "    scores = m.local_outlier_probabilities\n",
        "    scores_df['inception_pynomaly_loop_original'] = scores\n",
        "    binary_scores_df['inception_pynomaly_loop_original_binary'] = scores\n",
        "    binary_scores_df['inception_pynomaly_loop_original_binary'] = np.where(binary_scores_df['inception_pynomaly_loop_original_binary']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOP Config 1')\n",
        "\n",
        "  #parameters to test:\n",
        "  # -eps/min_samples for DBSCAN\n",
        "  # -extend/n_neighbors for LOP\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps01_sam10_nei10_e1'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam10_nei10_e1'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam10_nei10_e1'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam10_nei10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 1')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.1, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps01_sam20_nei10_e2'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam20_nei10_e2'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam20_nei10_e2'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam20_nei10_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 2')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.1, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, n_neighbors=20, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps01_sam20_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam20_nei20_e2'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam20_nei20_e2'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam20_nei20_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 3')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=10, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps01_sam50_nei10_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei10_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei10_e3'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei10_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 4')\n",
        "\n",
        "  try: \n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=20, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps01_sam50_nei20_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei20_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei20_e3'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei20_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 5')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.1, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, n_neighbors=50, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps01_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei50_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei50_e3'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps01_sam50_nei50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 6')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=10, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=1, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilitiesscores_df['inception_dbscan_scores_original_eps03_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam10_e1'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam10_e1'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam10_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 7')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=20, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps03_sam20_e2'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam20_e1'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam20_e1'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam20_e1']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 8')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=2,  cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps03_sam50_e2'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e2'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e2'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e2']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 9')\n",
        "\n",
        "  try:  \n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3,cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e3'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 10')\n",
        "\n",
        "  try:\n",
        "    db = DBSCAN(eps=0.3, min_samples=50, n_jobs=-1).fit(data)\n",
        "    m = loop.LocalOutlierProbability(data, extent=3, cluster_labels=list(db.labels_), progress_bar=True).fit()\n",
        "    scores_dbscan = m.local_outlier_probabilities\n",
        "    scores_df['inception_dbscan_scores_original_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e3'] = scores_dbscan\n",
        "    binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e3'] = np.where(binary_scores_df['inception_dbscan_scores_original_binary_eps03_sam50_e3']>=0.5, 1, 0)\n",
        "  except:\n",
        "    print('Exception Raised --> DBSCAN Config 11')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dd6oZjtDvyz"
      },
      "source": [
        "##sklearn algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCF1tx7TDvyz"
      },
      "outputs": [],
      "source": [
        "def sklearn_methods(data, scores_df, binary_scores_df):\n",
        "  #Minimum Covariance Determinant\n",
        "  try:\n",
        "    ee = EllipticEnvelope(contamination=0.001)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['inception_elliptic_decfunc_original_cont0.001'] = dec_func\n",
        "    scores_df['inception_elliptic_mahalanobis_original_cont0.001'] = maha\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.001'] = pred\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.001'] = np.where(binary_scores_df['inception_elliptic_env_original_binary_cont0.001']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 1')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.01)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['inception_elliptic_decfunc_original_cont0.01'] = dec_func\n",
        "    scores_df['inception_elliptic_mahalanobis_original_cont0.01'] = maha\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.01'] = pred\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.01'] = np.where(binary_scores_df['inception_elliptic_env_original_binary_cont0.01']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 2')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.1)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['inception_elliptic_decfunc_original_cont0.1'] = dec_func\n",
        "    scores_df['inception_elliptic_mahalanobis_original_cont0.1'] = maha\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.1'] = pred\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.1'] = np.where(binary_scores_df['inception_elliptic_env_original_binary_cont0.1']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 3')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.2)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['inception_elliptic_decfunc_original_cont0.2'] = dec_func\n",
        "    scores_df['inception_elliptic_mahalanobis_original_cont0.2'] = maha\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.2'] = pred\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.2'] = np.where(binary_scores_df['inception_elliptic_env_original_binary_cont0.2']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 4')\n",
        "\n",
        "  try:\n",
        "    #Minimum Covariance Determinant\n",
        "    ee = EllipticEnvelope(contamination=0.5)\n",
        "    score = ee.fit_predict(data)\n",
        "    dec_func = ee.decision_function(data)\n",
        "    maha = ee.mahalanobis(data)\n",
        "    pred = ee.predict(data)\n",
        "    scores_df['inception_elliptic_decfunc_original_cont0.5'] = dec_func\n",
        "    scores_df['inception_elliptic_mahalanobis_original_cont0.5'] = maha\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.5'] = pred\n",
        "    binary_scores_df['inception_elliptic_env_original_binary_cont0.5'] = np.where(binary_scores_df['inception_elliptic_env_original_binary_cont0.5']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Elliptic Envelope Config 5')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.001, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['inception_iso_forest_paper_score_original_cont0.001'] = original_paper_score\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.001'] = pred\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.001'] = np.where(binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.001']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 1')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.01, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['inception_iso_forest_paper_score_original_cont0.01'] = original_paper_score\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.01'] = pred\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.01'] = np.where(binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.01']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 2')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.1, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['inception_iso_forest_paper_score_original_cont0.1'] = original_paper_score\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.1'] = pred\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.1'] = np.where(binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.1']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 3')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.2, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['inception_iso_forest_paper_score_original_cont0.2'] = original_paper_score\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.2'] = pred\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.2'] = np.where(binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.2']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 4')\n",
        "\n",
        "  try:\n",
        "    #isolation forest\n",
        "    iso = IsolationForest(contamination=0.5, n_jobs=-1)\n",
        "    #returns -1 for outliers and +1 for inliers\n",
        "    pred = iso.fit_predict(data)\n",
        "    #using decision function i can obtain outlierness for each observation\n",
        "    sklearn_score_anomalies = iso.decision_function(data)\n",
        "    original_paper_score = [-1*s + 0.5 for s in sklearn_score_anomalies]\n",
        "    scores_df['inception_iso_forest_paper_score_original_cont0.5'] = original_paper_score\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.5'] = pred\n",
        "    binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.5'] = np.where(binary_scores_df['inception_iso_forest_paper_score_original_binary_cont0.5']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Forest Config 5')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=10, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['inception_lof_score_original_mink_nei10'] = lof_score\n",
        "    binary_scores_df['inception_lof_score_original_binary_mink_nei10'] = pred\n",
        "    binary_scores_df['inception_lof_score_original_binary_mink_nei10'] = np.where(binary_scores_df['inception_lof_score_original_binary_mink_nei10']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 1')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=20, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['inception_lof_score_original_mink_nei20'] = lof_score\n",
        "    binary_scores_df['inception_lof_score_original_binary_mink_nei20'] = pred\n",
        "    binary_scores_df['inception_lof_score_original_binary_mink_nei20'] = np.where(binary_scores_df['inception_lof_score_original_binary_mink_nei20']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 2')\n",
        "\n",
        "  try:\n",
        "    #Local Outlier Factor\n",
        "    lof = LocalOutlierFactor(novelty=True, metric='minkowski', n_neighbors=50, n_jobs=-1)\n",
        "    lof.fit(data)\n",
        "    lof_score = lof.decision_function(data)\n",
        "    pred = lof.predict(data)\n",
        "    scores_df['inception_lof_score_original_mink_nei50'] = lof_score\n",
        "    binary_scores_df['inception_lof_score_original_binary_mink_nei50'] = pred\n",
        "    binary_scores_df['inception_lof_score_original_binary_mink_nei50'] = np.where(binary_scores_df['inception_lof_score_original_binary_mink_nei50']==-1, 1,0)\n",
        "  except:\n",
        "    print('Exception Raised --> LOF Config 3')\n",
        "\n",
        "  # from sklearn.svm import OneClassSVM\n",
        "  # try:\n",
        "  #   #One Class SVM\n",
        "  #   ee = OneClassSVM(nu=0.001, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['inception_oneclass_SVM_original_linear_nu0.001'] = ocsvm_score\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.001'] = pred\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.001'] = np.where(binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.001']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 1')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.01, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['inception_oneclass_SVM_original_linear_nu0.01'] = ocsvm_score\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.01'] = pred\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.01'] = np.where(binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.01']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 2')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.1, kernel='linear')\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['inception_oneclass_SVM_original_linear_nu0.1'] = ocsvm_score\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.1'] = pred\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.1'] = np.where(binary_scores_df['inception_oneclass_SVM_original_binary_linear_nu0.1']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 3')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.001)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['inception_oneclass_SVM_original_rbf_nu0.001'] = ocsvm_score\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.001'] = pred\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.001'] = np.where(binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.001']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 4')\n",
        "\n",
        "  # try:  \n",
        "  #   ee = OneClassSVM(nu=0.01)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['inception_oneclass_SVM_original_rbf_nu0.01'] = ocsvm_score\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.01'] = pred\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.01'] = np.where(binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.01']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 5')\n",
        "\n",
        "  # try:\n",
        "  #   ee = OneClassSVM(nu=0.1)\n",
        "  #   pred = ee.fit_predict(data)\n",
        "  #   ocsvm_score = ee.decision_function(data)\n",
        "  #   scores_df['inception_oneclass_SVM_original_rbf_nu0.1'] = ocsvm_score\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.1'] = pred\n",
        "  #   binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.1'] = np.where(binary_scores_df['inception_oneclass_SVM_original_binary_rbf_nu0.1']==-1, 1,0)\n",
        "  # except:\n",
        "  #   print('Exception Raised --> One Class SVM Config 6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWwFOzG9Dvy0"
      },
      "source": [
        "##pyod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Tn7n23Dvy0"
      },
      "outputs": [],
      "source": [
        "from pyod.models.mcd import MCD\n",
        "from pyod.models.suod import SUOD\n",
        "from pyod.models.loda import LODA\n",
        "from pyod.models.feature_bagging import FeatureBagging\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.cof import COF\n",
        "from pyod.models.copod import COPOD\n",
        "from pyod.models.ecod import ECOD\n",
        "from pyod.models.sos import SOS\n",
        "from pyod.models.pca import PCA\n",
        "\n",
        "def pyod_methods(data, scores_df, binary_scores_df):\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['inception_pyod_copod_original_cont0.001'] = pyod_copod\n",
        "    binary_scores_df['inception_pyod_copod_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['inception_pyod_copod_original_cont0.01'] = pyod_copod\n",
        "    binary_scores_df['inception_pyod_copod_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['inception_pyod_copod_original_cont0.1'] = pyod_copod\n",
        "    binary_scores_df['inception_pyod_copod_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['inception_pyod_copod_original_cont0.2'] = pyod_copod\n",
        "    binary_scores_df['inception_pyod_copod_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = COPOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_copod = clf.decision_scores_  # raw outlier scores on the train data\n",
        "    scores_df['inception_pyod_copod_original_cont0.5'] = pyod_copod\n",
        "    binary_scores_df['inception_pyod_copod_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COPOD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ecod_original_cont0.001'] = pyod_ecod\n",
        "    binary_scores_df['inception_pyod_ecod_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ecod_original_cont0.01'] = pyod_ecod\n",
        "    binary_scores_df['inception_pyod_ecod_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ecod_original_cont0.1'] = pyod_ecod\n",
        "    binary_scores_df['inception_pyod_ecod_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ecod_original_cont0.2'] = pyod_ecod\n",
        "    binary_scores_df['inception_pyod_ecod_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = ECOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ecod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ecod_original_cont0.5'] = pyod_ecod\n",
        "    binary_scores_df['inception_pyod_ecod_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> ECOD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sos_original_cont0.001'] = pyod_sos\n",
        "    binary_scores_df['inception_pyod_sos_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sos_original_cont0.01'] = pyod_sos\n",
        "    binary_scores_df['inception_pyod_sos_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sos_original_cont0.1'] = pyod_sos\n",
        "    binary_scores_df['inception_pyod_sos_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sos_original_cont0.2'] = pyod_sos\n",
        "    binary_scores_df['inception_pyod_sos_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = SOS(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sos_original_cont0.5'] = pyod_sos\n",
        "    binary_scores_df['inception_pyod_sos_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SOS Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.001_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.001_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 1 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.01_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.01_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 2 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.1_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.1_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 3 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.2_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.2_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 4 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.5_whitFalse'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.5_whitFalse'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 5 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.001_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.001_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 6 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.01_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.01_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 7 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.1_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.1_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 8 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.2_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.2_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 9 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = PCA(n_components=2, contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_pca = clf.decision_scores_\n",
        "    scores_df['inception_pyod_pca_original_cont0.5_whitTrue'] = pyod_pca\n",
        "    binary_scores_df['inception_pyod_pca_original_binary_cont0.5_whitTrue'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> PCA Config 10 data maybe not converged')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mcd_original_cont0.001'] = pyod_mcd\n",
        "    binary_scores_df['inception_pyod_mcd_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mcd_original_cont0.01'] = pyod_mcd\n",
        "    binary_scores_df['inception_pyod_mcd_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mcd_original_cont0.1'] = pyod_mcd\n",
        "    binary_scores_df['inception_pyod_mcd_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mcd_original_cont0.2'] = pyod_mcd\n",
        "    binary_scores_df['inception_pyod_mcd_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = MCD(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mcd = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mcd_original_cont0.5'] = pyod_mcd\n",
        "    binary_scores_df['inception_pyod_mcd_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MCD Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.001_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.001_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.01_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.01_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.1_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.1_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.2_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.2_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.5_nu0.001'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.5_nu0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.001_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.001_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.001_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.001_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 7')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.001, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.001_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.001_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.01_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.001_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.01_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.001_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 10')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.01, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.01_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.001_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 11')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.1_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.1_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 12')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.1_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.1_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 13')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.1, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.1_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.1_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 14')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.2_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.2_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 15')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.2_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.2_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 16')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.2, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.2_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.2_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 17')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.5_nu0.1'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.5_nu0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 18')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.5_nu0.3'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.5_nu0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 19')\n",
        "\n",
        "  try:\n",
        "    clf = OCSVM(contamination=0.5, nu=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_ocsvm = clf.decision_scores_\n",
        "    scores_df['inception_pyod_ocsvm_original_cont0.5_nu0.5'] = pyod_ocsvm\n",
        "    binary_scores_df['inception_pyod_ocsvm_original_binary_cont0.5_nu0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> OCSVM Config 20')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.001_nei10'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.001_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.01_nei10'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.01_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.1_nei10'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.1_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.2_nei10'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.2_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=10)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.5_nei10'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.5_nei10'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.001_nei20'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.001_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 6')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.01_nei20'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.01_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 7')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.1_nei20'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.1_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 8')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.2_nei20'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.2_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 9')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=20)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.5_nei20'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.5_nei20'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 10')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.001, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.001_nei50'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.001_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 11')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.01, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.01_nei50'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.01_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 12')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.1, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.1_nei50'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.1_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 13')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.2, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.2_nei50'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.2_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 14')\n",
        "\n",
        "  try:\n",
        "    clf = COF(contamination=0.5, n_neighbors=50)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cof_original_cont0.5_nei50'] = pyod_cof\n",
        "    binary_scores_df['inception_pyod_cof_original_binary_cont0.5_nei50'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> COF Config 15')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cblof_original_cont0.001'] = pyod_cblof\n",
        "    binary_scores_df['inception_pyod_cblof_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 1')\n",
        "\n",
        "  try:  \n",
        "    clf = CBLOF(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cblof_original_cont0.01'] = pyod_cblof\n",
        "    binary_scores_df['inception_pyod_cblof_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cblof_original_cont0.1'] = pyod_cblof\n",
        "    binary_scores_df['inception_pyod_cblof_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cblof_original_cont0.2'] = pyod_cblof\n",
        "    binary_scores_df['inception_pyod_cblof_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = CBLOF(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_cblof = clf.decision_scores_\n",
        "    scores_df['inception_pyod_cblof_original_cont0.5'] = pyod_cblof\n",
        "    binary_scores_df['inception_pyod_cblof_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> CBLOF Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_hbos_original_cont0.001'] = pyod_hbos\n",
        "    binary_scores_df['inception_pyod_hbos_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_hbos_original_cont0.01'] = pyod_hbos\n",
        "    binary_scores_df['inception_pyod_hbos_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_hbos_original_cont0.1'] = pyod_hbos\n",
        "    binary_scores_df['inception_pyod_hbos_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_hbos_original_cont0.2'] = pyod_hbos\n",
        "    binary_scores_df['inception_pyod_hbos_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = HBOS(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_hbos = clf.decision_scores_\n",
        "    scores_df['inception_pyod_hbos_original_cont0.5'] = pyod_hbos\n",
        "    binary_scores_df['inception_pyod_hbos_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> HBOS Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['inception_pyod_knn_original_cont0.001'] = pyod_knn\n",
        "    binary_scores_df['inception_pyod_knn_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['inception_pyod_knn_original_cont0.01'] = pyod_knn\n",
        "    binary_scores_df['inception_pyod_knn_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 2')\n",
        "\n",
        "  try:  \n",
        "    clf = KNN(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['inception_pyod_knn_original_cont0.1'] = pyod_knn\n",
        "    binary_scores_df['inception_pyod_knn_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['inception_pyod_knn_original_cont0.2'] = pyod_knn\n",
        "    binary_scores_df['inception_pyod_knn_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = KNN(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_knn = clf.decision_scores_\n",
        "    scores_df['inception_pyod_knn_original_cont0.5'] = pyod_knn\n",
        "    binary_scores_df['inception_pyod_knn_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> KNN Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['inception_pyod_featbagg_original_cont0.001'] = pyod_featbagg\n",
        "    binary_scores_df['inception_pyod_featbagg_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['inception_pyod_featbagg_original_cont0.01'] = pyod_featbagg\n",
        "    binary_scores_df['inception_pyod_featbagg_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['inception_pyod_featbagg_original_cont0.1'] = pyod_featbagg\n",
        "    binary_scores_df['inception_pyod_featbagg_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['inception_pyod_featbagg_original_cont0.2'] = pyod_featbagg\n",
        "    binary_scores_df['inception_pyod_featbagg_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = FeatureBagging(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_featbagg = clf.decision_scores_\n",
        "    scores_df['inception_pyod_featbagg_original_cont0.5'] = pyod_featbagg\n",
        "    binary_scores_df['inception_pyod_featbagg_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Feature Bagging Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['inception_pyod_loda_original_cont0.001'] = pyod_loda\n",
        "    binary_scores_df['inception_pyod_loda_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['inception_pyod_loda_original_cont0.01'] = pyod_loda\n",
        "    binary_scores_df['inception_pyod_loda_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['inception_pyod_loda_original_cont0.1'] = pyod_loda\n",
        "    binary_scores_df['inception_pyod_loda_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['inception_pyod_loda_original_cont0.2'] = pyod_loda\n",
        "    binary_scores_df['inception_pyod_loda_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = LODA(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_loda = clf.decision_scores_\n",
        "    scores_df['inception_pyod_loda_original_cont0.5'] = pyod_loda\n",
        "    binary_scores_df['inception_pyod_loda_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> LODA Config 5')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.001, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_suod_original_cont0.001'] = pyod_suod\n",
        "    binary_scores_df['inception_pyod_suod_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 1')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.01, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_suod_original_cont0.01'] = pyod_suod\n",
        "    binary_scores_df['inception_pyod_suod_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 2')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.1, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_suod_original_cont0.1'] = pyod_suod\n",
        "    binary_scores_df['inception_pyod_suod_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 3')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.2, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_suod_original_cont0.2'] = pyod_suod\n",
        "    binary_scores_df['inception_pyod_suod_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 4')\n",
        "\n",
        "  try:\n",
        "    clf = SUOD(contamination=0.5, n_jobs=-1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_suod = clf.decision_scores_\n",
        "    scores_df['inception_pyod_suod_original_cont0.5'] = pyod_suod\n",
        "    binary_scores_df['inception_pyod_suod_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SUOD Config 5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7GKzFODDvy3"
      },
      "source": [
        "##network methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jILWeDisDvy3"
      },
      "outputs": [],
      "source": [
        "#autoencoder method - (improve network)\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "def network_methods(data):\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['inception_pyod_encoder_original_cont0.001'] = pyod_encoder\n",
        "    binary_scores_df['inception_pyod_encoder_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['inception_pyod_encoder_original_cont0.01'] = pyod_encoder\n",
        "    binary_scores_df['inception_pyod_encoder_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['inception_pyod_encoder_original_cont0.1'] = pyod_encoder\n",
        "    binary_scores_df['inception_pyod_encoder_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['inception_pyod_encoder_original_cont0.2'] = pyod_encoder\n",
        "    binary_scores_df['inception_pyod_encoder_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  try:\n",
        "    clf = AutoEncoder(epochs=200, hidden_neurons=[data.shape[1], data.shape[1]/2,data.shape[1]/2,data.shape[1]], contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_encoder = clf.decision_scores_\n",
        "    scores_df['inception_pyod_encoder_original_cont0.5'] = pyod_encoder\n",
        "    binary_scores_df['inception_pyod_encoder_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> Auto Encoder Config')\n",
        "\n",
        "  #vae method\n",
        "  from pyod.models.vae import VAE\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['inception_pyod_vae_original_cont0.001'] = pyod_vae\n",
        "    binary_scores_df['inception_pyod_vae_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['inception_pyod_vae_original_cont0.01'] = pyod_vae\n",
        "    binary_scores_df['inception_pyod_vae_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['inception_pyod_vae_original_cont0.1'] = pyod_vae\n",
        "    binary_scores_df['inception_pyod_vae_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['inception_pyod_vae_original_cont0.2'] = pyod_vae\n",
        "    binary_scores_df['inception_pyod_vae_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  try:\n",
        "    clf = VAE(epochs=200, encoder_neurons=[data.shape[1], data.shape[1]/2], decoder_neurons=[data.shape[1]/2,data.shape[1]], contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_vae = clf.decision_scores_\n",
        "    scores_df['inception_pyod_vae_original_cont0.5'] = pyod_vae\n",
        "    binary_scores_df['inception_pyod_vae_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> VAE Config')\n",
        "\n",
        "  #so_gaal method\n",
        "  from pyod.models.so_gaal import SO_GAAL\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.001, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.001_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.001_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.01, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.01_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.01_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.1_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.1_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.2, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.2_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.2_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.5, lr_d=0.0001 , lr_g=0.0001 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.5_lrd0.0001_lrg0.0001_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.5_lrd0.0001_lrg0.0001_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.1_lrd0.01_lrg0.01_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.1_lrd0.01_lrg0.01_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.3 , lr_g=0.3 ,momentum=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.1_lrd0.3_lrg0.3_mom0.01'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.1_lrd0.3_lrg0.3_mom0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.1_lrd0.01_lrg0.01_mom0.1'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.1_lrd0.01_lrg0.01_mom0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = SO_GAAL(contamination=0.1, lr_d=0.01 , lr_g=0.01 ,momentum=0.3)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_sogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_sogaal_original_cont0.1_lrd0.01_lrg0.01_mom0.3'] = pyod_sogaal\n",
        "    binary_scores_df['inception_pyod_sogaal_original_binary_cont0.1_lrd0.01_lrg0.01_mom0.3'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> SO GAAL Config')\n",
        "\n",
        "  #deepsvdd method\n",
        "  import pyod.models.deep_svdd\n",
        "  try:\n",
        "    clf = pyod.models.deep_svdd.DeepSVDD(verbose=1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd = clf.decision_scores_\n",
        "    scores_df['inception_pyod_svdd_original'] = pyod_svdd\n",
        "    binary_scores_df['inception_pyod_svdd_original_binary'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  #mo_gaal method\n",
        "  from pyod.models.mo_gaal import MO_GAAL\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mogaal_original_cont0.001'] = pyod_mogaal\n",
        "    binary_scores_df['inception_pyod_mogaal_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mogaal_original_cont0.01'] = pyod_mogaal\n",
        "    binary_scores_df['inception_pyod_mogaal_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mogaal_original_cont0.1'] = pyod_mogaal\n",
        "    binary_scores_df['inception_pyod_mogaal_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mogaal_original_cont0.2'] = pyod_mogaal\n",
        "    binary_scores_df['inception_pyod_mogaal_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  try:\n",
        "    clf = MO_GAAL(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_mogaal = clf.decision_scores_\n",
        "    scores_df['inception_pyod_mogaal_original_cont0.5'] = pyod_mogaal\n",
        "    binary_scores_df['inception_pyod_mogaal_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> MO GAAL Config')\n",
        "\n",
        "  #deep_svd method\n",
        "  from pyod.models.deep_svdd import DeepSVDD\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.001)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['inception_pyod_svdd_decfunc_original_cont0.001'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['inception_pyod_svdd_decfunc_original_binary_cont0.001'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.01)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['inception_pyod_svdd_decfunc_original_cont0.01'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['inception_pyod_svdd_decfunc_original_binary_cont0.01'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.1)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['inception_pyod_svdd_decfunc_original_cont0.1'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['inception_pyod_svdd_decfunc_original_binary_cont0.1'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.2)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['inception_pyod_svdd_decfunc_original_cont0.2'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['inception_pyod_svdd_decfunc_original_binary_cont0.2'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')\n",
        "\n",
        "  try:\n",
        "    clf = DeepSVDD(contamination=0.5)\n",
        "    clf.fit(data)\n",
        "    pred = clf.predict(data)\n",
        "    pyod_svdd_decfunc = clf.decision_scores_\n",
        "    scores_df['inception_pyod_svdd_decfunc_original_cont0.5'] = pyod_svdd_decfunc\n",
        "    binary_scores_df['inception_pyod_svdd_decfunc_original_binary_cont0.5'] = pred\n",
        "  except:\n",
        "    print('Exception Raised -> DEEP SVDD Config')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz8Om_gWD1vT"
      },
      "source": [
        "#DIMENSIONALITY REDUCTION TECHNIQUES ON PROJECTED FEATURES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v24wggrD1vT"
      },
      "outputs": [],
      "source": [
        "def sammon(x, n, display = 0, inputdist = 'raw', maxhalves = 20, maxiter = 1, tolfun = 1e-9, init = 'default'):\n",
        "\n",
        "    import numpy as np \n",
        "    from scipy.spatial.distance import cdist\n",
        "\n",
        "    \"\"\"Perform Sammon mapping on dataset x\n",
        "    y = sammon(x) applies the Sammon nonlinear mapping procedure on\n",
        "    multivariate data x, where each row represents a pattern and each column\n",
        "    represents a feature.  On completion, y contains the corresponding\n",
        "    co-ordinates of each point on the map.  By default, a two-dimensional\n",
        "    map is created.  Note if x contains any duplicated rows, SAMMON will\n",
        "    fail (ungracefully). \n",
        "    [y,E] = sammon(x) also returns the value of the cost function in E (i.e.\n",
        "    the ess of the mapping).\n",
        "    An N-dimensional output map is generated by y = sammon(x,n) .\n",
        "    A set of optimisation options can be specified using optional\n",
        "    arguments, y = sammon(x,n,[OPTS]):\n",
        "       maxiter        - maximum number of iterations\n",
        "       tolfun         - relative tolerance on objective function\n",
        "       maxhalves      - maximum number of step halvings\n",
        "       input          - {'raw','distance'} if set to 'distance', X is \n",
        "                        interpreted as a matrix of pairwise distances.\n",
        "       display        - 0 to 2. 0 least verbose, 2 max verbose.\n",
        "       init           - {'pca', 'cmdscale', random', 'default'}\n",
        "                        default is 'pca' if input is 'raw', \n",
        "                        'msdcale' if input is 'distance'\n",
        "    The default options are retrieved by calling sammon(x) with no\n",
        "    parameters.\n",
        "    File        : sammon.py\n",
        "    Date        : 18 April 2014\n",
        "    Authors     : Tom J. Pollard (tom.pollard.11@ucl.ac.uk)\n",
        "                : Ported from MATLAB implementation by \n",
        "                  Gavin C. Cawley and Nicola L. C. Talbot\n",
        "    Description : Simple python implementation of Sammon's non-linear\n",
        "                  mapping algorithm [1].\n",
        "    References  : [1] Sammon, John W. Jr., \"A Nonlinear Mapping for Data\n",
        "                  Structure Analysis\", IEEE Transactions on Computers,\n",
        "                  vol. C-18, no. 5, pp 401-409, May 1969.\n",
        "    Copyright   : (c) Dr Gavin C. Cawley, November 2007.\n",
        "    This program is free software; you can redistribute it and/or modify\n",
        "    it under the terms of the GNU General Public License as published by\n",
        "    the Free Software Foundation; either version 2 of the License, or\n",
        "    (at your option) any later version.\n",
        "    This program is distributed in the hope that it will be useful,\n",
        "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "    GNU General Public License for more details.\n",
        "    You should have received a copy of the GNU General Public License\n",
        "    along with this program; if not, write to the Free Software\n",
        "    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n",
        "    \"\"\"\n",
        "\n",
        "    # Create distance matrix unless given by parameters\n",
        "    if inputdist == 'distance':\n",
        "        D = x\n",
        "        if init == 'default':\n",
        "            init = 'cmdscale'\n",
        "    else:\n",
        "        D = cdist(x, x)\n",
        "        if init == 'default':\n",
        "            init = 'pca'\n",
        "\n",
        "    if inputdist == 'distance' and init == 'pca':\n",
        "        raise ValueError(\"Cannot use init == 'pca' when inputdist == 'distance'\")\n",
        "\n",
        "    if np.count_nonzero(np.diagonal(D)) > 0:\n",
        "        raise ValueError(\"The diagonal of the dissimilarity matrix must be zero\")\n",
        "\n",
        "    # Remaining initialisation\n",
        "    N = x.shape[0]\n",
        "    scale = 0.5 / D.sum()\n",
        "    D = D + np.eye(N)     \n",
        "\n",
        "    if np.count_nonzero(D<=0) > 0:\n",
        "        raise ValueError(\"Off-diagonal dissimilarities must be strictly positive\")   \n",
        "\n",
        "    Dinv = 1 / D\n",
        "    if init == 'pca':\n",
        "        [UU,DD,_] = np.linalg.svd(x)\n",
        "        y = UU[:,:n]*DD[:n] \n",
        "    elif init == 'cmdscale':\n",
        "        from cmdscale import cmdscale\n",
        "        y,e = cmdscale(D)\n",
        "        y = y[:,:n]\n",
        "    else:\n",
        "        y = np.random.normal(0.0,1.0,[N,n])\n",
        "    one = np.ones([N,n])\n",
        "    d = cdist(y,y) + np.eye(N)\n",
        "    dinv = 1. / d\n",
        "    delta = D-d \n",
        "    E = ((delta**2)*Dinv).sum() \n",
        "\n",
        "    # Get on with it\n",
        "    for i in range(maxiter):\n",
        "        # Compute gradient, Hessian and search direction (note it is actually\n",
        "        # 1/4 of the gradient and Hessian, but the step size is just the ratio\n",
        "        # of the gradient and the diagonal of the Hessian so it doesn't\n",
        "        # matter).\n",
        "        delta = dinv - Dinv\n",
        "        deltaone = np.dot(delta,one)\n",
        "        g = np.dot(delta,y) - (y * deltaone)\n",
        "        dinv3 = dinv ** 3\n",
        "        y2 = y ** 2\n",
        "        H = np.dot(dinv3,y2) - deltaone - np.dot(2,y) * np.dot(dinv3,y) + y2 * np.dot(dinv3,one)\n",
        "        s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))\n",
        "        y_old    = y\n",
        "\n",
        "        # Use step-halving procedure to ensure progress is made\n",
        "        for j in range(maxhalves):\n",
        "            s_reshape = np.reshape(s, (-1,n),order='F')\n",
        "            y = y_old + s_reshape\n",
        "            d = cdist(y, y) + np.eye(N)\n",
        "            dinv = 1 / d\n",
        "            delta = D - d\n",
        "            E_new = ((delta**2)*Dinv).sum()\n",
        "            if E_new < E:\n",
        "                break\n",
        "            else:\n",
        "                s = 0.5*s\n",
        "\n",
        "        # Bomb out if too many halving steps are required\n",
        "        if j == maxhalves-1:\n",
        "            print('Warning: maxhalves exceeded. Sammon mapping may not converge...')\n",
        "\n",
        "        # Evaluate termination criterion\n",
        "        if abs((E - E_new) / E) < tolfun:\n",
        "            if display:\n",
        "                print('TolFun exceeded: Optimisation terminated')\n",
        "            break\n",
        "\n",
        "        # Report progress\n",
        "        E = E_new\n",
        "        if display > 1:\n",
        "            print('epoch = %d : E = %12.10f'% (i+1, E * scale))\n",
        "\n",
        "    if i == maxiter-1:\n",
        "        print('Warning: maxiter exceeded. Sammon mapping may not have converged...')\n",
        "\n",
        "    # Fiddle stress to match the original Sammon paper\n",
        "    E = E * scale\n",
        "    \n",
        "    return [y,E]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw04x-ufD1vU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import random_projection\n",
        "from sklearn.manifold import Isomap\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import KernelPCA\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn import manifold\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.ticker import NullFormatter\n",
        "\n",
        "#create new dataframes. they will contain principal components extracted from different dimensionality reduction techniques\n",
        "#df_dimredu contains components extracted from outlierness scores\n",
        "#df_dataredu contains components extracted from original data\n",
        "\n",
        "df_dimredu = pd.DataFrame()\n",
        "df_dataredu = pd.DataFrame()\n",
        "df_binredu = pd.DataFrame()\n",
        "\n",
        "def dim_redu_methods(data, scores_df, binary_scores_df):\n",
        "  pca = PCA(n_components=2)\n",
        "  out_pca = pd.DataFrame()\n",
        "  out_pca_scores = pd.DataFrame()\n",
        "  out_pca_bin = pd.DataFrame()\n",
        "  try:\n",
        "    pca.fit(data)\n",
        "    out_pca = pd.DataFrame(pca.transform(data), index=data.index)\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 1')\n",
        "\n",
        "  try:\n",
        "    pca.fit(scores_df)\n",
        "    out_pca_scores = pd.DataFrame(pca.transform(scores_df), index=scores_df.index)\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 2')\n",
        "\n",
        "  try:\n",
        "    pca.fit(binary_scores_df)\n",
        "    out_pca_bin = pd.DataFrame(pca.transform(binary_scores_df), index=binary_scores_df.index)\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config 3')\n",
        "\n",
        "  try:\n",
        "    df_dataredu['inception_pca1_data'] = out_pca[0]\n",
        "    df_dataredu['inception_pca2_data'] = out_pca[1]\n",
        "    df_dimredu['inception_pca1_scores'] = out_pca_scores[0]\n",
        "    df_dimredu['inception_pca2_scores'] = out_pca_scores[1]\n",
        "    df_binredu['inception_pca1_binary'] = out_pca_bin[0]\n",
        "    df_binredu['inception_pca2_binary'] = out_pca_bin[1]\n",
        "  except:\n",
        "    print('Exception Raised --> PCA Config loading')\n",
        "\n",
        "  rsp = random_projection.GaussianRandomProjection(n_components=2)\n",
        "  try:\n",
        "    ran_proj = rsp.fit_transform(scores_df)\n",
        "    df_dimredu['inception_sub_proj1_scores'] = ran_proj[:,0]\n",
        "    df_dimredu['inception_sub_proj2_scores'] = ran_proj[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Random Projection Config scores')\n",
        "\n",
        "  try:  \n",
        "    ran_proj_data = rsp.fit_transform(data)\n",
        "    df_dataredu['inception_sub_proj1_data'] = ran_proj_data[:,0]\n",
        "    df_dataredu['inception_sub_proj2_data'] = ran_proj_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Random Projection Config data')\n",
        "\n",
        "  try:\n",
        "    ran_proj_bin = rsp.fit_transform(binary_scores_df)\n",
        "    df_binredu['inception_sub_proj1_binary'] = ran_proj_bin[:,0]\n",
        "    df_binredu['inception_sub_proj2_binary'] = ran_proj_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Random Projection Config binary')\n",
        "\n",
        "  iso = Isomap(n_components=2)\n",
        "\n",
        "  try:\n",
        "    iso_proj = iso.fit_transform(scores_df)\n",
        "    df_dimredu['inception_iso_map_1_scores'] = iso_proj[:,0]\n",
        "    df_dimredu['inception_iso_map_2_scores'] = iso_proj[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Map Config scores')\n",
        "\n",
        "  try:\n",
        "    iso_proj_data = iso.fit_transform(data)\n",
        "    df_dataredu['inception_iso_map_1_data'] = iso_proj_data[:,0]\n",
        "    df_dataredu['inception_iso_map_2_data'] = iso_proj_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Map Config data')\n",
        "\n",
        "  try:  \n",
        "    iso_proj_bin = iso.fit_transform(binary_scores_df)\n",
        "    df_binredu['inception_iso_map_1_binary'] = iso_proj_bin[:,0]\n",
        "    df_binredu['inception_iso_map_2_binary'] = iso_proj_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Iso Map Config binary')\n",
        "\n",
        "  tsne = TSNE(n_components=2)\n",
        "\n",
        "  try:\n",
        "    sne_proj = tsne.fit_transform(scores_df)\n",
        "    df_dimredu['inception_sne_1_scores'] = sne_proj[:,0]\n",
        "    df_dimredu['inception_sne_2_scores'] = sne_proj[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> TSNE Config scores')\n",
        "\n",
        "  try:  \n",
        "    sne_proj_data = tsne.fit_transform(data)\n",
        "    df_dataredu['inception_sne_1_data'] = sne_proj_data[:,0]\n",
        "    df_dataredu['inception_sne_2_data'] = sne_proj_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> TSNE Config data')\n",
        "\n",
        "  try:\n",
        "    sne_proj_bin = tsne.fit_transform(binary_scores_df)\n",
        "    df_binredu['inception_sne_1_binary'] = sne_proj_bin[:,0]\n",
        "    df_binredu['inception_sne_2_binary'] = sne_proj_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> TSNE Config binary')\n",
        "\n",
        "  clf = LinearDiscriminantAnalysis()\n",
        "\n",
        "  try:\n",
        "    clf.fit(scores_df, target)\n",
        "    lda_proj = clf.transform(scores_df)\n",
        "    df_dimredu['inception_lda_1_scores_0'] = lda_proj[0:lda_proj.shape[0], 0]\n",
        "    df_dimredu['inception_lda_1_scores_1'] = lda_proj[0:lda_proj.shape[0], 1]\n",
        "    df_dimredu['inception_lda_1_scores_2'] = lda_proj[0:lda_proj.shape[0], 2]\n",
        "    df_dimredu['inception_lda_1_scores_3'] = lda_proj[0:lda_proj.shape[0], 3]\n",
        "    df_dimredu['inception_lda_1_scores_4'] = lda_proj[0:lda_proj.shape[0], 4]\n",
        "    df_dimredu['inception_lda_1_scores_5'] = lda_proj[0:lda_proj.shape[0], 5]\n",
        "    df_dimredu['inception_lda_1_scores_6'] = lda_proj[0:lda_proj.shape[0], 6]\n",
        "    df_dimredu['inception_lda_1_scores_7'] = lda_proj[0:lda_proj.shape[0], 7]\n",
        "    df_dimredu['inception_lda_1_scores_8'] = lda_proj[0:lda_proj.shape[0], 8]\n",
        "    df_dimredu['inception_lda_1_scores_9'] = lda_proj[0:lda_proj.shape[0], 9]\n",
        "    df_dimredu['inception_lda_1_scores_10'] = lda_proj[0:lda_proj.shape[0], 10]\n",
        "  except:\n",
        "    print('Exception Raised --> Linear Discriminant Analysis (classes exceeded)')\n",
        "\n",
        "  try:\n",
        "    clf.fit(data, target)\n",
        "    lda_proj_data = clf.transform(data)\n",
        "    df_dataredu['inception_lda_1_data_0'] = lda_proj_data[0:lda_proj_data.shape[0], 0]\n",
        "    df_dataredu['inception_lda_1_data_1'] = lda_proj_data[0:lda_proj_data.shape[0], 1]\n",
        "    df_dataredu['inception_lda_1_data_2'] = lda_proj_data[0:lda_proj_data.shape[0], 2]\n",
        "    df_dataredu['inception_lda_1_data_3'] = lda_proj_data[0:lda_proj_data.shape[0], 3]\n",
        "    df_dataredu['inception_lda_1_data_4'] = lda_proj_data[0:lda_proj_data.shape[0], 4]\n",
        "    df_dataredu['inception_lda_1_data_5'] = lda_proj_data[0:lda_proj_data.shape[0], 5]\n",
        "    df_dataredu['inception_lda_1_data_6'] = lda_proj_data[0:lda_proj_data.shape[0], 6]\n",
        "    df_dataredu['inception_lda_1_data_7'] = lda_proj_data[0:lda_proj_data.shape[0], 7]\n",
        "    df_dataredu['inception_lda_1_data_8'] = lda_proj_data[0:lda_proj_data.shape[0], 8]\n",
        "    df_dataredu['inception_lda_1_data_9'] = lda_proj_data[0:lda_proj_data.shape[0], 9]\n",
        "    df_dataredu['inception_lda_1_data_10'] = lda_proj_data[0:lda_proj_data.shape[0], 10]\n",
        "  except:\n",
        "    print('Exception Raised --> Linear Discriminant Analysis Config (classes exceeded)')\n",
        "\n",
        "  try:\n",
        "    clf.fit(binary_scores_df, target)\n",
        "    lda_proj_bin = clf.transform(binary_scores_df) \n",
        "    df_binredu['inception_lda_1_binary_0'] = lda_proj_bin[0:lda_proj_bin.shape[0], 0]\n",
        "    df_binredu['inception_lda_1_binary_1'] = lda_proj_bin[0:lda_proj_bin.shape[0], 1]\n",
        "    df_binredu['inception_lda_1_binary_2'] = lda_proj_bin[0:lda_proj_bin.shape[0], 2]\n",
        "    df_binredu['inception_lda_1_binary_3'] = lda_proj_bin[0:lda_proj_bin.shape[0], 3]\n",
        "    df_binredu['inception_lda_1_binary_4'] = lda_proj_bin[0:lda_proj_bin.shape[0], 4]\n",
        "    df_binredu['inception_lda_1_binary_5'] = lda_proj_bin[0:lda_proj_bin.shape[0], 5]\n",
        "    df_binredu['inception_lda_1_binary_6'] = lda_proj_bin[0:lda_proj_bin.shape[0], 6]\n",
        "    df_binredu['inception_lda_1_binary_7'] = lda_proj_bin[0:lda_proj_bin.shape[0], 7]\n",
        "    df_binredu['inception_lda_1_binary_8'] = lda_proj_bin[0:lda_proj_bin.shape[0], 8]\n",
        "    df_binredu['inception_lda_1_binary_9'] = lda_proj_bin[0:lda_proj_bin.shape[0], 9]\n",
        "    df_binredu['inception_lda_1_binary_10'] = lda_proj_bin[0:lda_proj_bin.shape[0], 10]\n",
        "  except:\n",
        "    print('Exception Raised --> Linear Discriminant Analysis Config (classes exceeded)')\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='rbf', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['inception_rbf_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['inception_rbf_pca_2_scores'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 1')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['inception_rbf_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['inception_rbf_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 1')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['inception_rbf_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['inception_rbf_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 1')\n",
        "\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='cosine', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['inception_cosine_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['inception_cosine_pca_2_scores'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 2')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['inception_cosine_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['inception_cosine_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 2')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['inception_cosine_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['inception_cosine_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 2')\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='sigmoid', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['inception_sigmoid_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['inception_sigmoid_pca_2_scores'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 3')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['inception_sigmoid_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['inception_sigmoid_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 3')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['inception_sigmoid_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['inception_sigmoid_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 3')\n",
        "\n",
        "  kpca = KernelPCA(n_components=2, kernel='poly', \n",
        "                  gamma=15, random_state=42)\n",
        "\n",
        "  try:\n",
        "    X_kpca = kpca.fit_transform(scores_df)\n",
        "    df_dimredu['inception_poly_pca_1_scores'] = X_kpca[:,0]\n",
        "    df_dimredu['inception_poly_pca_2_scores_'] = X_kpca[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config scores 4')\n",
        "\n",
        "  try:\n",
        "    X_kpca_data = kpca.fit_transform(data)\n",
        "    df_dataredu['inception_poly_pca_1_data'] = X_kpca_data[:,0]\n",
        "    df_dataredu['inception_poly_pca_2_data'] = X_kpca_data[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config data 4')\n",
        "\n",
        "  try:\n",
        "    X_kpca_bin = kpca.fit_transform(binary_scores_df)\n",
        "    df_binredu['inception_poly_pca_1_binary'] = X_kpca_bin[:,0]\n",
        "    df_binredu['inception_poly_pca_2_binary'] = X_kpca_bin[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Kernel PCA Config binary 4')\n",
        "\n",
        "  #convert two scores in numeric, to perform sammon function\n",
        "  if 'inception_pynomaly_loop_original' in scores_df.columns:\n",
        "    scores_df[\"inception_pynomaly_loop_original\"] = pd.to_numeric(scores_df[\"inception_pynomaly_loop_original\"])\n",
        "  #scores_df[\"dbscan_scores_original\"] = pd.to_numeric(scores_df[\"dbscan_scores_original\"])\n",
        "\n",
        "  try:\n",
        "    # By default, sammon returns a 2-dim array and the error E\n",
        "    [y, E] = sammon(data, maxiter=20, n=2)\n",
        "    [y2, E2] = sammon(scores_df, maxiter=20, n=2)\n",
        "\n",
        "    df_dataredu['inception_sammon_1_data'] = y[:,0]\n",
        "    df_dataredu['inception_sammon_2_data'] = y[:,1]\n",
        "    df_dimredu['inception_sammon_1_scores'] = y2[:,0]\n",
        "    df_dimredu['inception_sammon_2_scores'] = y2[:,1]\n",
        "  except:\n",
        "    print('Exception Raised --> Sammon Mapping Config')\n",
        "\n",
        "  try:\n",
        "    Axes3D\n",
        "    n_neighbors = 100\n",
        "    n_components = 2\n",
        "    # Set-up manifold methods\n",
        "    LLE = partial(manifold.LocallyLinearEmbedding, n_neighbors=n_neighbors, n_components=n_components, eigen_solver=\"auto\")\n",
        "    methods = OrderedDict()\n",
        "    methods[\"LLE\"] = LLE(method=\"standard\")\n",
        "    methods[\"Hessian LLE\"] = LLE(method=\"hessian\", eigen_solver='dense')\n",
        "    methods[\"Modified LLE\"] = LLE(method=\"modified\", eigen_solver='dense')\n",
        "    methods[\"MDS\"] = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
        "    methods[\"SE\"] = manifold.SpectralEmbedding(n_components=n_components, n_neighbors=n_neighbors)\n",
        "  except:\n",
        "    print('Exception Raised -> MainFold Methods Inizialization')\n",
        "  try:\n",
        "    for i, (label, method) in enumerate(methods.items()):\n",
        "      Y = method.fit_transform(scores_df)\n",
        "      Y2 = method.fit_transform(data)\n",
        "      str1 = label+\"_1inception_\"\n",
        "      str2 = label+\"_2inception_\"  \n",
        "      \n",
        "      if(label!='Modified LLE'):\n",
        "        Y3 = method.fit_transform(binary_scores_df)\n",
        "        df_binredu[str1+\"_binary\"] = Y3[:,0]\n",
        "        df_binredu[str2+\"_binary\"] = Y3[:,1]      \n",
        "      \n",
        "      df_dimredu[str1+\"_scores\"] = Y[:,0]\n",
        "      df_dimredu[str2+\"_scores\"] = Y[:,1]\n",
        "      df_dataredu[str1+\"_data\"] = Y2[:,0]\n",
        "      df_dataredu[str2+\"_data\"] = Y2[:,1]\n",
        "      print(\"%s Completed\" % (label))\n",
        "  except:\n",
        "    print('Exception Raised --> MainFold Methods Calculus')\n",
        "\n",
        "  try:\n",
        "    # Fixed dimensions\n",
        "    input_dim = data.shape[1]\n",
        "    encoding_dim = 2\n",
        "    # Number of neurons in each Layer [8, 6, 4, 3, ...] of encoders\n",
        "    input_layer = Input(shape=(input_dim, ))\n",
        "    encoder_layer_1 = Dense(18, activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "    encoder_layer_2 = Dense(9, activation=\"tanh\")(encoder_layer_1)\n",
        "    encoder_layer_3 = Dense(7, activation=\"tanh\")(encoder_layer_2)\n",
        "    encoder_layer_4 = Dense(5, activation=\"relu\")(encoder_layer_3)\n",
        "    encoder_layer_5 = Dense(3, activation=\"relu\")(encoder_layer_4)\n",
        "    encoder_layer_6 = Dense(encoding_dim, activation=\"sigmoid\")(encoder_layer_5)\n",
        "\n",
        "    # Crear encoder model\n",
        "    encoder = Model(inputs=input_layer, outputs=encoder_layer_6)\n",
        "    # Use the model to predict the factors which sum up the information of interest rates.\n",
        "    encoded_data = pd.DataFrame(encoder.predict(data))\n",
        "    encoded_data.columns = ['factor_1', 'factor_2']\n",
        "\n",
        "    # Fixed dimensions\n",
        "    input_dim = scores_df.shape[1]\n",
        "    encoding_dim = 2\n",
        "    # Number of neurons in each Layer [8, 6, 4, 3, ...] of encoders\n",
        "    input_layer = Input(shape=(input_dim, ))\n",
        "    encoder_layer_1 = Dense(18, activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "    encoder_layer_2 = Dense(9, activation=\"relu\")(encoder_layer_1)\n",
        "    encoder_layer_3 = Dense(7, activation=\"relu\")(encoder_layer_2)\n",
        "    encoder_layer_4 = Dense(5, activation=\"relu\")(encoder_layer_3)\n",
        "    encoder_layer_5 = Dense(3, activation=\"relu\")(encoder_layer_4)\n",
        "    encoder_layer_6 = Dense(encoding_dim, activation=\"sigmoid\")(encoder_layer_5)\n",
        "\n",
        "    # Crear encoder model\n",
        "    encoder = Model(inputs=input_layer, outputs=encoder_layer_6)\n",
        "    # Use the model to predict the factors which sum up the information of interest rates.\n",
        "    encoded_scores = pd.DataFrame(encoder.predict(scores_df))\n",
        "    encoded_scores.columns = ['factor_1', 'factor_2']\n",
        "\n",
        "    # Fixed dimensions\n",
        "    input_dim = binary_scores_df.shape[1]\n",
        "    encoding_dim = 2\n",
        "    # Number of neurons in each Layer [8, 6, 4, 3, ...] of encoders\n",
        "    input_layer = Input(shape=(input_dim, ))\n",
        "    encoder_layer_1 = Dense(18, activation=\"relu\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "    encoder_layer_2 = Dense(9, activation=\"relu\")(encoder_layer_1)\n",
        "    encoder_layer_3 = Dense(7, activation=\"relu\")(encoder_layer_2)\n",
        "    encoder_layer_4 = Dense(5, activation=\"relu\")(encoder_layer_3)\n",
        "    encoder_layer_5 = Dense(3, activation=\"relu\")(encoder_layer_4)\n",
        "    encoder_layer_6 = Dense(encoding_dim, activation=\"sigmoid\")(encoder_layer_5)\n",
        "\n",
        "    # Crear encoder model\n",
        "    encoder = Model(inputs=input_layer, outputs=encoder_layer_6)\n",
        "    # Use the model to predict the factors which sum up the information of interest rates.\n",
        "    encoded_bin = pd.DataFrame(encoder.predict(binary_scores_df))\n",
        "    encoded_bin.columns = ['factor_1', 'factor_2']\n",
        "\n",
        "    df_dataredu['inception_autoencoder_1_data'] = encoded_data['factor_1']\n",
        "    df_dataredu['inception_autoencoder_2_data'] = encoded_data['factor_2']\n",
        "    df_dimredu['inception_autoencoder_1_scores'] = encoded_scores['factor_1']\n",
        "    df_dimredu['inception_autoencoder_2_scores'] = encoded_scores['factor_2']\n",
        "    df_binredu['inception_autoencoder_1_binary'] = encoded_bin['factor_1']\n",
        "    df_binredu['inception_autoencoder_2_binary'] = encoded_bin['factor_2']\n",
        "  except:\n",
        "    print('Exception Raised --> AutoEncoder Config')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuzd5QUtD88d"
      },
      "source": [
        "#APPLY FEATURE EXTRACTION PIPELINE ON PROJECTED FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXHCoq7bD88d"
      },
      "outputs": [],
      "source": [
        "def extract_outlierness_features(data, pynomaly=True, sklearn=True, pyod=True, network=True):\n",
        "  if(pynomaly==True):\n",
        "    pynomaly_methods(data, scores_df, binary_scores_df)\n",
        "  if(sklearn==True):\n",
        "    sklearn_methods(data, scores_df, binary_scores_df)\n",
        "  if(pyod==True):\n",
        "    pyod_methods(data, scores_df, binary_scores_df)\n",
        "  if(network==True):\n",
        "    network_methods(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCqXbF11D88e"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print('Outlierness Scores Extraction: \\n')\n",
        "extract_outlierness_features(data, pynomaly=True,sklearn=True,pyod=True,network=False) #anomaly detection methods applied on outlierness scores\n",
        "\n",
        "#normalize outlierness scores\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "scores_df = pd.DataFrame(scaler.fit_transform(scores_df), columns=scores_df.columns)\n",
        "\n",
        "print('\\nNull Values in Outlierness Scores DataSets:')\n",
        "print('Scores_df: ')\n",
        "scores_df.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "scores_df.loc[:, scores_df.isna().any()]\n",
        "print('--- --- ---')\n",
        "print('Binary_Scores_df: ')\n",
        "binary_scores_df.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "binary_scores_df.loc[:, binary_scores_df.isna().any()]\n",
        "print('--- --- ---')\n",
        "\n",
        "#save outlierness numeric and binary scores to .csv\n",
        "scores_df.to_csv(directory + \"inception_outlierness_scores.csv\")\n",
        "binary_scores_df.to_csv(directory + \"inception_binary_scores.csv\")\n",
        "\n",
        "#apply dimensionality reduction methods on principal components\n",
        "print('\\n--- --- --- --- ---\\nDimensionality Reduction Features Extraction: ')\n",
        "\n",
        "\n",
        "dim_redu_methods(data2, scores_df, binary_scores_df)\n",
        "\n",
        "print('\\nNull Values in Dimensionality Reduction DataSets:')\n",
        "df_dataredu.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=True)\n",
        "print(df_dataredu.isnull().sum())\n",
        "print('--- --- ---')\n",
        "\n",
        "#normalize calculated principal components\n",
        "scaler = RobustScaler()\n",
        "df_dataredu = pd.DataFrame(scaler.fit_transform(df_dataredu), columns=df_dataredu.columns)\n",
        "\n",
        "#save dimensionality reduction (applied on principal components) to .csv\n",
        "df_dataredu.to_csv(directory + \"inception_dim_redu_original_data.csv\")\n",
        "\n",
        "end = time.time()\n",
        "#save first feature extraction phase time ellapsed\n",
        "print(\"Support Features Extraction Time: %.8s seconds\" % (end - start_time))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VVbkG54Q9TEL",
        "OlthKTNg9Xb9",
        "8wf4nrXner8I",
        "fl37YIJeiF-W",
        "53YmYDLOmhIq",
        "2IubCDytiCbG",
        "hMFjoc6umjPl",
        "Gm7Spm8f6gIT",
        "6H9dBtOaOpyP",
        "c-1PW4MHDATY",
        "s-5r-qRIDATY",
        "_bOjTQ72DATZ",
        "CrEhovdYDATZ",
        "W0h5MIoF35Zs",
        "mKjSFOGnDvyt",
        "C9jnsMkKDvyt",
        "8dd6oZjtDvyz",
        "eWwFOzG9Dvy0",
        "b7GKzFODDvy3",
        "fz8Om_gWD1vT",
        "kuzd5QUtD88d"
      ],
      "name": "[step1] FEATURE_EXTRACTION (ORIGINAL DATA) ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}